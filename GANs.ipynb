{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GANs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNyc/rP+P2lIjdbuhsi643r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tejaspradhan/GANs-Masterclass/blob/main/GANs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIMXQgcPumCz"
      },
      "source": [
        "# Coding a Generative Adversarial Network in Tensorflow for the MNIST Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIjGBECIuxYn"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsyyHiiuGTCR"
      },
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf \n",
        "import time"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWbxbZNEu0oI"
      },
      "source": [
        "# Downloading & Exploring the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEOJcwQpGaYj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21e806af-b16d-479d-e721-d75ac7658c0d"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()  "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "1Qxc4XyCGmlT",
        "outputId": "1a57eac2-7cbf-4576-ed97-c18e93ba7b5e"
      },
      "source": [
        "plt.imshow(train_images[1] ,cmap='gray')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f3ce37e62d0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2qlUgrOu_iF"
      },
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "In this, we perform 2 main tasks : \n",
        "1. **Normalisation**\n",
        "  \n",
        "  Here we perform standard normalisation to bring the pixel values of the images between `-1 and 1`. For this we use the formula \n",
        "  \n",
        "  **`Normalised value = (Given Value - (MaxVal-MinVal/2)) / (MaxVal-MinVal/2)`**\n",
        "  \n",
        "  Generally, the pixel values are ranging from `0 to 255`. Computing such huge numbers becomes extremely cumbersome for neural networks and it might lead to the problem of exploding gradients. To avoid this normalization of data is always preferred. We can also perform normalisation using minmax scaler to bring the data in the range of `0 to 1`.\n",
        "\n",
        "2. **Expanding Dimensions of the Images**\n",
        "\n",
        "  This step is mainly performed because convolutional neural networks require 1 image in 3-dimensions. So even though are images have only 1 channel (Grayscale), we need to reshape them so that each image has one dimension extra. This is done either by using `expanddims` or `reshape`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kT3Y7UGBNY7W"
      },
      "source": [
        "# Normalization\n",
        "train_images= (train_images-127.5)/127.5"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "XzO1Up1KPJ1h",
        "outputId": "00690346-962c-4d74-a721-f1fb5a84af1d"
      },
      "source": [
        "plt.imshow(train_images[1],cmap='gray')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f3ce32c0a90>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWwk7GYvHELY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06d8722b-6d20-4bc1-c507-7e95920349cc"
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aKfJS5zNS68",
        "outputId": "63f04195-5863-46cd-d9aa-8ddb5b30fa7c"
      },
      "source": [
        "# Expanding dimensions\n",
        "train_images = train_images.reshape(train_images.shape[0],train_images.shape[1],train_images.shape[2],1)\n",
        "train_images.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWRsEG-POaDJ"
      },
      "source": [
        "# Defining training size parameters\n",
        "BUFFER_SIZE = 60000 # what is the total number of samples to be trained ?\n",
        "BATCH_SIZE = 256 # how many training samples should the neural network look at - at one point or during one epoch"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_AmY1jEOc2H"
      },
      "source": [
        "# Batchwise shuffling of the dataset - to avoid mode collapse and overfitting \n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G94T_C2oPqRh"
      },
      "source": [
        "## Building The Discriminator \n",
        "\n",
        "The discriminator is essentially a binary crossentropy. We define a custom method to return a classifier model with convolutional as well as dense layers and a final Dense neuron. The discriminator can be thought of as a conventional CNN. \n",
        "\n",
        "Steps for building the Discriminator \n",
        "\n",
        "* Define model layers \n",
        "* Define model loss\n",
        "* Define model optimizer \n",
        "\n",
        "**Loss For Discrimintor**: \n",
        "\n",
        "The discriminator takes input from the real as well as the fake samples. Loss for the discriminator is therefore, the sum of fake loss and real loss.\n",
        "In order to pass the ground truth / true values to the loss function we use the `ones_like` and `zeros_like` functions. These two functions take in an array or tensor as an input and output a tensor with the same shape consisting of just ones or zeros\n",
        "\n",
        "e.g: \n",
        "\n",
        "`tf.ones_like([1,2,3,4,5]) => [1,1,1,1,1]`\n",
        "\n",
        "`tf.zeros_like([1,2,3,4,5]) => [0,0,0,0,0]`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "In1NjbwEPv8o"
      },
      "source": [
        "# Essentially a CNN model \n",
        "def discriminator():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  \n",
        "  model.add(tf.keras.layers.Conv2D(7,(3,3),padding='same',input_shape=(28,28,1)))\n",
        "  model.add(tf.keras.layers.Conv2D(7,(3,3),padding='same'))\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(50,activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(1))\n",
        "  return model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qB8TyvTiQifM"
      },
      "source": [
        "# optimizer for the discriminator\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHz4O2ITQsoK"
      },
      "source": [
        "# loss function for the discriminator \n",
        "def discriminator_loss(real_predictions, fake_predictions):\n",
        "  # passing both the outputs through a sigmoid activation so as to get the probability values\n",
        "  real_predictions = tf.sigmoid(real_predictions) \n",
        "  fake_predictions = tf.sigmoid(fake_predictions)\n",
        "\n",
        "  # Computing binary crossentropy loss \n",
        "  real_loss = tf.keras.losses.binary_crossentropy(tf.ones_like(real_predictions), real_predictions)\n",
        "  fake_loss = tf.keras.losses.binary_crossentropy(tf.zeros_like(fake_predictions),fake_predictions)\n",
        "  \n",
        "  # returning final losses\n",
        "  if real_loss.shape == fake_loss.shape:\n",
        "    return real_loss+fake_loss\n",
        "  else:\n",
        "    return fake_loss+0.1\n",
        "  "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRv7SGHqRDX5",
        "outputId": "b1fb3b7b-4020-42ca-e376-3fd396001077"
      },
      "source": [
        "discriminator().summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 7)         70        \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 7)         448       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 5488)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 50)                274450    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 275,019\n",
            "Trainable params: 275,019\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqNHc6mPQ20z"
      },
      "source": [
        "## Building the Generator \n",
        "\n",
        "The generator is a neural network which takes in a random noise input and produces an output which is extremely similar to the real data. In this problem the output should be a `28x28` image. The input to the generator is a tensor of 100 random numbers.\n",
        "\n",
        "The generator follows a process of upsampling, i.e., generating `784 pixels` from 100 input values which are then rescaled to a `28x28` image. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBz-OGsuSqbG"
      },
      "source": [
        "def generator():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(7*7*256,input_shape =(100,)))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Dense(7*7*256))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Reshape( (7,7,256) ))\n",
        "  model.add(tf.keras.layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same'))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same'))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same'))\n",
        "  return model"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2XQ-Br1Q1ZF",
        "outputId": "b216520f-584e-4337-85d0-4b05cf4a4eff"
      },
      "source": [
        "generator().summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 12544)             1266944   \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 12544)             50176     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 12544)             157364480 \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 12544)             50176     \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose (Conv2DTran (None, 7, 7, 128)         819328    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 64)        204864    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 1)         1601      \n",
            "=================================================================\n",
            "Total params: 159,758,337\n",
            "Trainable params: 159,707,777\n",
            "Non-trainable params: 50,560\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrtQfiFsU9MB"
      },
      "source": [
        "def generator_loss(fake_predictions):\n",
        "  fake_predictions = tf.sigmoid(fake_predictions)\n",
        "  fake_loss = tf.keras.losses.binary_crossentropy(tf.ones_like(fake_predictions),fake_predictions)\n",
        "  return fake_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbZRwnYOU_p5"
      },
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWPIMCR5XRhc"
      },
      "source": [
        "generator_model= generator()\n",
        "discriminator_model = discriminator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2h3XQDzVT_q"
      },
      "source": [
        "## Training the GAN\n",
        "Training the GAN involves the following steps \n",
        "  1. Training the Discriminator\n",
        "    \n",
        "    a. Passing real and fake data through the discriminator.\n",
        "\n",
        "    b. Calculating the discriminator loss\n",
        "\n",
        "    c. Passing this loss through the optimiser.\n",
        "\n",
        "  2. Training the Generator\n",
        "\n",
        "    a. Passing fake data through the generator.\n",
        "\n",
        "    b. Calculating generator loss\n",
        "\n",
        "    c. Passing this loss through the optimiser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsaiHuhpVe6l"
      },
      "source": [
        "def train(data, epochs):\n",
        "  for i in range(epochs):\n",
        "    for images in data:\n",
        "      images = tf.cast(images,tf.dtypes.float32)\n",
        "      train_step(images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BqRJHuVVwLR"
      },
      "source": [
        "def train_step(images):\n",
        "  noise = np.random.randn(BATCH_SIZE, 100).astype('float32')\n",
        "  # batchwise training \n",
        "  with tf.GradientTape() as generator_tape, tf.GradientTape() as discriminator_tape:\n",
        "        # Create fake images \n",
        "        generated_images = generator_model(noise)\n",
        "        # Pass fake images through the discriminator \n",
        "        generator_output = discriminator_model(generated_images)\n",
        "        # Pass real images through the discriminator \n",
        "        real_output = discriminator_model(images)\n",
        "\n",
        "        # calculate individual losses\n",
        "        gen_loss = generator_loss(generator_output)\n",
        "        disc_loss = discriminator_loss(real_output, generator_output)\n",
        "        \n",
        "        # Calculate gradients of loss functions\n",
        "        generator_gradients= generator_tape.gradient(gen_loss,generator_model.trainable_variables)\n",
        "        discriminator_gradients = discriminator_tape.gradient(disc_loss, discriminator_model.trainable_variables)\n",
        "        \n",
        "        # Optimise\n",
        "        generator_optimizer.apply_gradients(zip(generator_gradients, generator_model.trainable_variables))\n",
        "        discriminator_optimizer.apply_gradients(zip(discriminator_gradients, discriminator_model.trainable_variables))\n",
        "        \n",
        "        print(\"Generator Loss: \",np.mean(gen_loss))\n",
        "        print(\"Discriminator Loss: \",np.mean(disc_loss))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xGbk6W1FWT_Z",
        "outputId": "5454e557-b093-48ee-a2d1-368c368dc853"
      },
      "source": [
        "train(train_dataset,100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.182232\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762966\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164008\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223907\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.82286\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223906\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044219\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762963\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583279\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002548\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.2838\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002545\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583276\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.06244\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104116\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122339\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.70307\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361919\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.00255\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283801\n",
            "Generator Loss:  4.7600427\n",
            "Discriminator Loss:  10.601504\n",
            "Generator Loss:  4.820297\n",
            "Discriminator Loss:  10.541603\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122343\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223906\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  4.579282\n",
            "Discriminator Loss:  10.781186\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223906\n",
            "Generator Loss:  5.543341\n",
            "Discriminator Loss:  9.822861\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  4.519028\n",
            "Discriminator Loss:  10.841082\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583279\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.663849\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.984323\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.4817095\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.12234\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242128\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.46349\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882755\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002546\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302022\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.421814\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583276\n",
            "Generator Loss:  5.6035943\n",
            "Discriminator Loss:  9.762964\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283799\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523391\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.04422\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.3436985\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343695\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403593\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223904\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  4.7600427\n",
            "Discriminator Loss:  10.601501\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002546\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122337\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361921\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.24213\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403591\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762964\n",
            "Generator Loss:  5.061311\n",
            "Discriminator Loss:  10.302023\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882755\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924427\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52339\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164008\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541605\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.182235\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523382\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.421814\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302024\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463487\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.984324\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122337\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283806\n",
            "Generator Loss:  4.7600427\n",
            "Discriminator Loss:  10.601507\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164008\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703069\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.82286\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223904\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.98436\n",
            "Generator Loss:  5.3023257\n",
            "Discriminator Loss:  10.062441\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463488\n",
            "Generator Loss:  5.2420726\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942651\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942652\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  4.5190277\n",
            "Discriminator Loss:  10.841082\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643173\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942656\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.182231\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.182232\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122339\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.182233\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122336\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583279\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.46349\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002547\n",
            "Generator Loss:  5.543341\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  4.88055\n",
            "Discriminator Loss:  10.481708\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.58328\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661396\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.421814\n",
            "Generator Loss:  4.940804\n",
            "Discriminator Loss:  10.421814\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  4.88055\n",
            "Discriminator Loss:  10.481711\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302023\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.06244\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583281\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.24213\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.182233\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703072\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463499\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122337\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.70307\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.70307\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762964\n",
            "Generator Loss:  6.748415\n",
            "Discriminator Loss:  8.624952\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762963\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.48171\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002546\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.2838\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242128\n",
            "Generator Loss:  6.0856237\n",
            "Discriminator Loss:  9.283802\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523384\n",
            "Generator Loss:  5.6035943\n",
            "Discriminator Loss:  9.762964\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541603\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762964\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361932\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343694\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822858\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  6.3868923\n",
            "Discriminator Loss:  8.984325\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002545\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762967\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122336\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.182231\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804635\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583279\n",
            "Generator Loss:  5.2420726\n",
            "Discriminator Loss:  10.122337\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223905\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882755\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  5.543341\n",
            "Discriminator Loss:  9.822858\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882755\n",
            "Generator Loss:  4.5190277\n",
            "Discriminator Loss:  10.841082\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.58328\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361919\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104113\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223905\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  6.5074005\n",
            "Discriminator Loss:  8.8645315\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.182232\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822858\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.182231\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.2838\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343695\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062441\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942652\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302023\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523382\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822861\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762964\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481709\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643173\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822858\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523381\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583278\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242127\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.16401\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283809\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703067\n",
            "Generator Loss:  6.6279078\n",
            "Discriminator Loss:  8.744743\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822862\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882754\n",
            "Generator Loss:  6.6881614\n",
            "Discriminator Loss:  8.684844\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.984323\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942664\n",
            "Generator Loss:  6.0856237\n",
            "Discriminator Loss:  9.283804\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.563484\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.82286\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822858\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104114\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541613\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361918\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.421817\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.8645315\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.06244\n",
            "Generator Loss:  5.2420726\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463487\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463487\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523382\n",
            "Generator Loss:  6.748415\n",
            "Discriminator Loss:  8.6249485\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.061311\n",
            "Discriminator Loss:  10.302024\n",
            "Generator Loss:  4.820297\n",
            "Discriminator Loss:  10.541603\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.7030735\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643177\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523381\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.182232\n",
            "Generator Loss:  4.579282\n",
            "Discriminator Loss:  10.781185\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762964\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822861\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  6.0856247\n",
            "Discriminator Loss:  9.2838\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.06244\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583278\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.3619175\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361919\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.421812\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643173\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541603\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.864531\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.182232\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882759\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.58328\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.3619175\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403591\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882755\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762964\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.70307\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  4.5792813\n",
            "Discriminator Loss:  10.781187\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242128\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463487\n",
            "Generator Loss:  4.7600427\n",
            "Discriminator Loss:  10.6015\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.04422\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  4.639535\n",
            "Discriminator Loss:  10.7212925\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062454\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481709\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044218\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643173\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.70307\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302024\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361917\n",
            "Generator Loss:  6.748415\n",
            "Discriminator Loss:  8.6249485\n",
            "Generator Loss:  4.3985205\n",
            "Discriminator Loss:  10.960874\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523381\n",
            "Generator Loss:  5.543341\n",
            "Discriminator Loss:  9.822858\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924426\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002546\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  4.579282\n",
            "Discriminator Loss:  10.781188\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643173\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.543341\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361918\n",
            "Generator Loss:  4.6395354\n",
            "Discriminator Loss:  10.7212925\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882755\n",
            "Generator Loss:  5.2420726\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882754\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403592\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.182234\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104113\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302023\n",
            "Generator Loss:  4.760043\n",
            "Discriminator Loss:  10.6015\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.58328\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541606\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.6035943\n",
            "Discriminator Loss:  9.762964\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302027\n",
            "Generator Loss:  4.760043\n",
            "Discriminator Loss:  10.6015\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122337\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643173\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541605\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.30202\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643172\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762964\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361917\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.5416355\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463485\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403591\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882754\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822858\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942652\n",
            "Generator Loss:  5.543341\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283799\n",
            "Generator Loss:  5.543341\n",
            "Discriminator Loss:  9.82286\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661395\n",
            "Generator Loss:  5.784355\n",
            "Discriminator Loss:  9.583278\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.70307\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242128\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661396\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541607\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.182233\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  4.88055\n",
            "Discriminator Loss:  10.481716\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643173\n",
            "Generator Loss:  6.8086686\n",
            "Discriminator Loss:  8.565065\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  4.097252\n",
            "Discriminator Loss:  11.260351\n",
            "Generator Loss:  5.061311\n",
            "Discriminator Loss:  10.302023\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523382\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882755\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882755\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.182234\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283802\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583276\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242127\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302023\n",
            "Generator Loss:  5.0613117\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523384\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703069\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822858\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  4.7600427\n",
            "Discriminator Loss:  10.601511\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762964\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523383\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.182234\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643173\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.2239065\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.00255\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283799\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643173\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283799\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403592\n",
            "Generator Loss:  4.940804\n",
            "Discriminator Loss:  10.421814\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223904\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.421814\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882755\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822863\n",
            "Generator Loss:  6.5074005\n",
            "Discriminator Loss:  8.8645315\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762967\n",
            "Generator Loss:  6.5074005\n",
            "Discriminator Loss:  8.864531\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703072\n",
            "Generator Loss:  5.061311\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164009\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583276\n",
            "Generator Loss:  4.579282\n",
            "Discriminator Loss:  10.781189\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.864531\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062441\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044218\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822858\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403591\n",
            "Generator Loss:  4.6395354\n",
            "Discriminator Loss:  10.72129\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.82286\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164008\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361917\n",
            "Generator Loss:  4.6395354\n",
            "Discriminator Loss:  10.721291\n",
            "Generator Loss:  6.688161\n",
            "Discriminator Loss:  8.684846\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463487\n",
            "Generator Loss:  6.0856247\n",
            "Discriminator Loss:  9.2838\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044222\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481709\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.864531\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223904\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.182232\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242128\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.182232\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361918\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223906\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703067\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.864532\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223904\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  4.7600427\n",
            "Discriminator Loss:  10.601501\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481708\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924427\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.3619175\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481709\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  10.042648\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302022\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403596\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942651\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223906\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002545\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.182232\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.24213\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.06244\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463485\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062441\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523382\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661394\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002547\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361917\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762964\n",
            "Generator Loss:  5.3023257\n",
            "Discriminator Loss:  10.062441\n",
            "Generator Loss:  4.88055\n",
            "Discriminator Loss:  10.4817095\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643172\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223906\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924428\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643173\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942654\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062443\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643173\n",
            "Generator Loss:  4.88055\n",
            "Discriminator Loss:  10.481707\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882755\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.24213\n",
            "Generator Loss:  5.543341\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  6.688161\n",
            "Discriminator Loss:  8.684845\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223931\n",
            "Generator Loss:  4.7600427\n",
            "Discriminator Loss:  10.601499\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822861\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523381\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.3619175\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403591\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.40359\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583278\n",
            "Generator Loss:  5.543341\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643173\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.2421255\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882754\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.182231\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403591\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343706\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762966\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403592\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.40359\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583276\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703067\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.06245\n",
            "Generator Loss:  4.6395354\n",
            "Discriminator Loss:  10.721293\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924426\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583281\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302022\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343694\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762963\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164009\n",
            "Generator Loss:  5.3625803\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302027\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942651\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.4817095\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062443\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541603\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.984322\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361916\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942656\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882763\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643172\n",
            "Generator Loss:  4.88055\n",
            "Discriminator Loss:  10.48171\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.9843235\n",
            "Generator Loss:  5.6035943\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343695\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361916\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002548\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  6.3868923\n",
            "Discriminator Loss:  8.9843235\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164008\n",
            "Generator Loss:  4.458774\n",
            "Discriminator Loss:  10.900978\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762964\n",
            "Generator Loss:  4.3382673\n",
            "Discriminator Loss:  11.020767\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.30202\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.2421255\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703069\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302023\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164009\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002545\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882756\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.0613117\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523382\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643173\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661394\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  4.639535\n",
            "Discriminator Loss:  10.7212925\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403593\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643172\n",
            "Generator Loss:  4.5190277\n",
            "Discriminator Loss:  10.841081\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062441\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223904\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463488\n",
            "Generator Loss:  4.7600427\n",
            "Discriminator Loss:  10.6015\n",
            "Generator Loss:  5.6035943\n",
            "Discriminator Loss:  9.762964\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343695\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002546\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044218\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.984321\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.421814\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.6035943\n",
            "Discriminator Loss:  9.762963\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.2838\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882754\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.421812\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703072\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  4.6395354\n",
            "Discriminator Loss:  10.72129\n",
            "Generator Loss:  4.639535\n",
            "Discriminator Loss:  10.72129\n",
            "Generator Loss:  4.760043\n",
            "Discriminator Loss:  10.601499\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223906\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523382\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.182233\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703067\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924427\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  4.940804\n",
            "Discriminator Loss:  10.421812\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541605\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  4.88055\n",
            "Discriminator Loss:  10.481709\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044216\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002554\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.06244\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822858\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  6.5074005\n",
            "Discriminator Loss:  8.864531\n",
            "Generator Loss:  4.940804\n",
            "Discriminator Loss:  10.421812\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  6.0856237\n",
            "Discriminator Loss:  9.2838\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062441\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361918\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062441\n",
            "Generator Loss:  6.2663856\n",
            "Discriminator Loss:  9.104113\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541603\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403594\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661394\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283801\n",
            "Generator Loss:  4.6395354\n",
            "Discriminator Loss:  10.721291\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.3619175\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.2421255\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481709\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703067\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403588\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481708\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.00255\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343694\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463487\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  4.458774\n",
            "Discriminator Loss:  10.900977\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703067\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822858\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804634\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.62338\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.182231\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062444\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223904\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.182232\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223905\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.82286\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.182232\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164009\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223905\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361917\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703069\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643172\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.3619175\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.06244\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  6.5074005\n",
            "Discriminator Loss:  8.864531\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242136\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822861\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.2421255\n",
            "Generator Loss:  4.88055\n",
            "Discriminator Loss:  10.48171\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  4.5792813\n",
            "Discriminator Loss:  10.781189\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  4.5792813\n",
            "Discriminator Loss:  10.781191\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583302\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661394\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.06244\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481709\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  6.5074005\n",
            "Discriminator Loss:  8.864531\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583276\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.3023257\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  6.6279078\n",
            "Discriminator Loss:  8.74474\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122336\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463487\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223904\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643172\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541603\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  5.4830866\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302023\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361917\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343696\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002546\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583281\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.06244\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.182233\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002548\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062441\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343696\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.061311\n",
            "Discriminator Loss:  10.302022\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302023\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643173\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343694\n",
            "Generator Loss:  3.9767444\n",
            "Discriminator Loss:  11.380144\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242136\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583278\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002545\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044216\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122336\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463485\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.1215653\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002545\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463487\n",
            "Generator Loss:  5.543341\n",
            "Discriminator Loss:  9.822858\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.421814\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822858\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643173\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343695\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403593\n",
            "Generator Loss:  4.5190277\n",
            "Discriminator Loss:  10.84108\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643172\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.36192\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523383\n",
            "Generator Loss:  6.748415\n",
            "Discriminator Loss:  8.6249485\n",
            "Generator Loss:  6.3868923\n",
            "Discriminator Loss:  8.984322\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.2838\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361917\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.061311\n",
            "Discriminator Loss:  10.302022\n",
            "Generator Loss:  4.7600427\n",
            "Discriminator Loss:  10.6015\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  6.3868923\n",
            "Discriminator Loss:  8.984321\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481709\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302022\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104112\n",
            "Generator Loss:  4.5190277\n",
            "Discriminator Loss:  10.841082\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.06244\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583278\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062442\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541604\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762963\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.421812\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762964\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  4.579282\n",
            "Discriminator Loss:  10.781185\n",
            "Generator Loss:  4.88055\n",
            "Discriminator Loss:  10.481707\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583276\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283799\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.182235\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  4.7600427\n",
            "Discriminator Loss:  10.601498\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882756\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.3619175\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  4.7600427\n",
            "Discriminator Loss:  10.6015\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523381\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583276\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062441\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.421814\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541603\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223903\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403592\n",
            "Generator Loss:  4.940804\n",
            "Discriminator Loss:  10.421812\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.06244\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283811\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  6.5074005\n",
            "Discriminator Loss:  8.864533\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.70307\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.3619175\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703067\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882755\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164006\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463485\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.3619175\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104112\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541604\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.3619175\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223905\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.864532\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223903\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703067\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  4.579282\n",
            "Discriminator Loss:  10.781185\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002551\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.3619175\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.982753\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.864531\n",
            "Generator Loss:  6.2663856\n",
            "Discriminator Loss:  9.104115\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122337\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703067\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  6.1458783\n",
            "Discriminator Loss:  9.223904\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  5.2420726\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302023\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223905\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.2838\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361917\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.182232\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104114\n",
            "Generator Loss:  5.543341\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.3619175\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661394\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  6.748415\n",
            "Discriminator Loss:  8.6249485\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  4.4587746\n",
            "Discriminator Loss:  10.900984\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882754\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  6.6279078\n",
            "Discriminator Loss:  8.744739\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  4.88055\n",
            "Discriminator Loss:  10.481709\n",
            "Generator Loss:  6.6881614\n",
            "Discriminator Loss:  8.684843\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481709\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403591\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643174\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.182231\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361924\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361917\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643173\n",
            "Generator Loss:  4.940804\n",
            "Discriminator Loss:  10.421812\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104114\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523382\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361917\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.421812\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.06244\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822858\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.3619175\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104114\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104112\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583276\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523383\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882755\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  4.6395354\n",
            "Discriminator Loss:  10.721289\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223905\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583276\n",
            "Generator Loss:  5.543341\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302023\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302022\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  4.7600427\n",
            "Discriminator Loss:  10.601499\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403592\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002546\n",
            "Generator Loss:  4.579282\n",
            "Discriminator Loss:  10.781185\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481709\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062441\n",
            "Generator Loss:  6.3868923\n",
            "Discriminator Loss:  8.98432\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  4.940804\n",
            "Discriminator Loss:  10.421812\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643172\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  4.7600427\n",
            "Discriminator Loss:  10.601499\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.06244\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.2421255\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.2421255\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703067\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481709\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924425\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104113\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  6.0856247\n",
            "Discriminator Loss:  9.283801\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541603\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643172\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343696\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104112\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643172\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002546\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523382\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.2421255\n",
            "Generator Loss:  5.0613117\n",
            "Discriminator Loss:  10.302023\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361917\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643174\n",
            "Generator Loss:  5.3023257\n",
            "Discriminator Loss:  10.062441\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.40361\n",
            "Generator Loss:  5.061311\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062438\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882757\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463485\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  4.458774\n",
            "Discriminator Loss:  10.900976\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583276\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002546\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062443\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583276\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.421814\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703067\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463488\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481707\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  4.7600427\n",
            "Discriminator Loss:  10.6015\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481709\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.9843235\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104112\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361919\n",
            "Generator Loss:  5.061311\n",
            "Discriminator Loss:  10.302023\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.864531\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062441\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  4.338267\n",
            "Discriminator Loss:  11.020767\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.182236\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  4.940804\n",
            "Discriminator Loss:  10.421812\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.984322\n",
            "Generator Loss:  6.748415\n",
            "Discriminator Loss:  8.6249485\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361917\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  4.338267\n",
            "Discriminator Loss:  11.020767\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  5.2420726\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  5.8446097\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343697\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661394\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463485\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062443\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.182229\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643173\n",
            "Generator Loss:  5.061311\n",
            "Discriminator Loss:  10.302025\n",
            "Generator Loss:  4.639535\n",
            "Discriminator Loss:  10.721291\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  6.5074005\n",
            "Discriminator Loss:  8.864531\n",
            "Generator Loss:  5.0613117\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481709\n",
            "Generator Loss:  5.543341\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002552\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523381\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822861\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343694\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.864531\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.421813\n",
            "Generator Loss:  4.579282\n",
            "Discriminator Loss:  10.781185\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.40359\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661394\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.7613945\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822858\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.2421255\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661393\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283799\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242131\n",
            "Generator Loss:  4.88055\n",
            "Discriminator Loss:  10.481707\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343695\n",
            "Generator Loss:  5.0613117\n",
            "Discriminator Loss:  10.302023\n",
            "Generator Loss:  5.543341\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104114\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361916\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661394\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.6035943\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.06244\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.182231\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  4.4587746\n",
            "Discriminator Loss:  10.900985\n",
            "Generator Loss:  6.5074005\n",
            "Discriminator Loss:  8.864531\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.2421255\n",
            "Generator Loss:  6.688161\n",
            "Discriminator Loss:  8.684845\n",
            "Generator Loss:  6.567654\n",
            "Discriminator Loss:  8.804636\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361917\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002546\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164011\n",
            "Generator Loss:  5.061311\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541602\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  4.7600427\n",
            "Discriminator Loss:  10.601498\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583276\n",
            "Generator Loss:  4.7600427\n",
            "Discriminator Loss:  10.601499\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  6.567654\n",
            "Discriminator Loss:  8.804634\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343694\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361918\n",
            "Generator Loss:  4.6395354\n",
            "Discriminator Loss:  10.721292\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583276\n",
            "Generator Loss:  4.88055\n",
            "Discriminator Loss:  10.481709\n",
            "Generator Loss:  4.6395354\n",
            "Discriminator Loss:  10.721289\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.984321\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  4.4587746\n",
            "Discriminator Loss:  10.900974\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104113\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302023\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661394\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.40359\n",
            "Generator Loss:  4.639535\n",
            "Discriminator Loss:  10.72129\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924425\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044216\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762963\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122337\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283804\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.06244\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  6.6881614\n",
            "Discriminator Loss:  8.684845\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.2421255\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  4.5190277\n",
            "Discriminator Loss:  10.841083\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942654\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762964\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044216\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343694\n",
            "Generator Loss:  4.579282\n",
            "Discriminator Loss:  10.781185\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122336\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223903\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541603\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044216\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361917\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361917\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062441\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104113\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343695\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  6.6279078\n",
            "Discriminator Loss:  8.74474\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002545\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  4.940804\n",
            "Discriminator Loss:  10.421812\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361917\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463485\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481708\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122337\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882758\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.421812\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882755\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343694\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.7030735\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  4.7600427\n",
            "Discriminator Loss:  10.601499\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481707\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.06244\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223904\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822858\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104113\n",
            "Generator Loss:  4.7600427\n",
            "Discriminator Loss:  10.601498\n",
            "Generator Loss:  6.447147\n",
            "Discriminator Loss:  8.924425\n",
            "Generator Loss:  4.579282\n",
            "Discriminator Loss:  10.781185\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822858\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.2420726\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343694\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481709\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343694\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661394\n",
            "Generator Loss:  4.6395354\n",
            "Discriminator Loss:  10.721291\n",
            "Generator Loss:  5.2420726\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  6.748415\n",
            "Discriminator Loss:  8.624949\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822862\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242128\n",
            "Generator Loss:  4.579282\n",
            "Discriminator Loss:  10.781204\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  5.2420726\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.2421255\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361917\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.82286\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164006\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.864531\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.543341\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  6.0856247\n",
            "Discriminator Loss:  9.283799\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.3619175\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.061311\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  10.042648\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583276\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122336\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  4.940804\n",
            "Discriminator Loss:  10.421812\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361917\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.40359\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481707\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  6.8086686\n",
            "Discriminator Loss:  8.565052\n",
            "Generator Loss:  6.2663856\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361917\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541609\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.182229\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.182229\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361916\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343694\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361918\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541609\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  4.639535\n",
            "Discriminator Loss:  10.721289\n",
            "Generator Loss:  6.0856237\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.2838\n",
            "Generator Loss:  4.579282\n",
            "Discriminator Loss:  10.781184\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403588\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.182232\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541604\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463485\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  4.7600427\n",
            "Discriminator Loss:  10.601499\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  4.519028\n",
            "Discriminator Loss:  10.841082\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403593\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882754\n",
            "Generator Loss:  4.519028\n",
            "Discriminator Loss:  10.84108\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.2421255\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882754\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361917\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643173\n",
            "Generator Loss:  4.940804\n",
            "Discriminator Loss:  10.421812\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924426\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361916\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  6.748415\n",
            "Discriminator Loss:  8.624948\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  4.278013\n",
            "Discriminator Loss:  11.080662\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.3619175\n",
            "Generator Loss:  5.3625803\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  4.7600427\n",
            "Discriminator Loss:  10.6015\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.2421255\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.2421255\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.061311\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463485\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924425\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  4.639535\n",
            "Discriminator Loss:  10.72129\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.2421255\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  4.6395354\n",
            "Discriminator Loss:  10.72129\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.182232\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882755\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  4.760043\n",
            "Discriminator Loss:  10.601498\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583276\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.06244\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661394\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661394\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541603\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924425\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002546\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403591\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804635\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583278\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.182229\n",
            "Generator Loss:  5.061311\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942647\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.182231\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541603\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  6.748415\n",
            "Discriminator Loss:  8.624948\n",
            "Generator Loss:  4.88055\n",
            "Discriminator Loss:  10.481707\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.00255\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882754\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403587\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924425\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283799\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.421814\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223903\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661395\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523381\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822866\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223904\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104113\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.543341\n",
            "Discriminator Loss:  9.822856\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.421812\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762978\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062438\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541603\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463485\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122336\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822858\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.06244\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463485\n",
            "Generator Loss:  5.061311\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541605\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  6.5074005\n",
            "Discriminator Loss:  8.8645315\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  4.458774\n",
            "Discriminator Loss:  10.900976\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703067\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.402021\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044216\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  4.940804\n",
            "Discriminator Loss:  10.421813\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.8446097\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002548\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.70307\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002546\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703067\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  4.579282\n",
            "Discriminator Loss:  10.781185\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.30202\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822858\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.182232\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.182229\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  5.543341\n",
            "Discriminator Loss:  9.822858\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703067\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924425\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  4.6395354\n",
            "Discriminator Loss:  10.721289\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924425\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.06244\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343695\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361917\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302023\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.421811\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  4.5190277\n",
            "Discriminator Loss:  10.841082\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481707\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463483\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942647\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  6.6279078\n",
            "Discriminator Loss:  8.744739\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361918\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822858\n",
            "Generator Loss:  6.0856237\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.543341\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  5.0613117\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703067\n",
            "Generator Loss:  4.579282\n",
            "Discriminator Loss:  10.781184\n",
            "Generator Loss:  4.5190277\n",
            "Discriminator Loss:  10.84108\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361916\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.2420726\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  5.3023257\n",
            "Discriminator Loss:  10.062437\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.2421255\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703067\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283799\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122336\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  6.6881614\n",
            "Discriminator Loss:  8.684844\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661393\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  4.458774\n",
            "Discriminator Loss:  10.900976\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  6.3868933\n",
            "Discriminator Loss:  8.984322\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661394\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541602\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403588\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.421812\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361917\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822858\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062445\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661394\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463485\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822858\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804635\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  4.4587746\n",
            "Discriminator Loss:  10.900976\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703067\n",
            "Generator Loss:  6.868922\n",
            "Discriminator Loss:  8.505157\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.82286\n",
            "Generator Loss:  4.7600427\n",
            "Discriminator Loss:  10.601498\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.421812\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703067\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361917\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044216\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044216\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.182229\n",
            "Generator Loss:  4.5190277\n",
            "Discriminator Loss:  10.841081\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122336\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.182229\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361917\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583276\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822858\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  5.0613117\n",
            "Discriminator Loss:  10.302022\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882757\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541603\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.421812\n",
            "Generator Loss:  5.663849\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  4.7600427\n",
            "Discriminator Loss:  10.601498\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  6.6279078\n",
            "Discriminator Loss:  8.744738\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  6.0856247\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122348\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  5.4830866\n",
            "Discriminator Loss:  9.882758\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104112\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.2421255\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463485\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.3619175\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062438\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.2421255\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.6035943\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  4.579282\n",
            "Discriminator Loss:  10.781184\n",
            "Generator Loss:  4.940804\n",
            "Discriminator Loss:  10.421812\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661396\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.922857\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343694\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.06244\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541602\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361916\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302019\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044216\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  4.940804\n",
            "Discriminator Loss:  10.42181\n",
            "Generator Loss:  4.940804\n",
            "Discriminator Loss:  10.421811\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  6.5074005\n",
            "Discriminator Loss:  8.864531\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.30202\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.182229\n",
            "Generator Loss:  5.784355\n",
            "Discriminator Loss:  9.583279\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361916\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.42181\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924425\n",
            "Generator Loss:  4.7600427\n",
            "Discriminator Loss:  10.601497\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804634\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223903\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122337\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463485\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481707\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.2421255\n",
            "Generator Loss:  6.6881614\n",
            "Discriminator Loss:  8.684844\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  6.0856237\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942647\n",
            "Generator Loss:  4.940804\n",
            "Discriminator Loss:  10.421812\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.30202\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.2421255\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.864531\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463485\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  4.940804\n",
            "Discriminator Loss:  10.421813\n",
            "Generator Loss:  4.579282\n",
            "Discriminator Loss:  10.781185\n",
            "Generator Loss:  4.7600427\n",
            "Discriminator Loss:  10.601498\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.421818\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583276\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.061311\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  4.458774\n",
            "Discriminator Loss:  10.900974\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  5.0613117\n",
            "Discriminator Loss:  10.302022\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  4.3985205\n",
            "Discriminator Loss:  10.960871\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.2421255\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.2421255\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223904\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  4.88055\n",
            "Discriminator Loss:  10.481707\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804634\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481708\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164006\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164005\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804633\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044217\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164008\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  5.543341\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122337\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541601\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804635\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583288\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.864533\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361921\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822856\n",
            "Generator Loss:  4.3382664\n",
            "Discriminator Loss:  11.020767\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541601\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361916\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  6.3868933\n",
            "Discriminator Loss:  8.98432\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361915\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.421811\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.421812\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661394\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361916\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.543341\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062438\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.6035943\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  6.5074\n",
            "Discriminator Loss:  8.864529\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.543341\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  4.820297\n",
            "Discriminator Loss:  10.541602\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.543341\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104112\n",
            "Generator Loss:  5.6035943\n",
            "Discriminator Loss:  9.762963\n",
            "Generator Loss:  6.5074005\n",
            "Discriminator Loss:  8.864529\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481708\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  4.820297\n",
            "Discriminator Loss:  10.541603\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062441\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  6.688161\n",
            "Discriminator Loss:  8.684843\n",
            "Generator Loss:  4.5792813\n",
            "Discriminator Loss:  10.781185\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822856\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  6.0856247\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403588\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  4.639535\n",
            "Discriminator Loss:  10.721288\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463485\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062438\n",
            "Generator Loss:  5.061311\n",
            "Discriminator Loss:  10.30202\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062441\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661394\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361916\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.162438\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  4.940804\n",
            "Discriminator Loss:  10.42181\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002556\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  6.0856247\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  5.3023257\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463485\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924425\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703067\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403588\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403588\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541601\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523382\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283799\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661393\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.06244\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541602\n",
            "Generator Loss:  4.7600427\n",
            "Discriminator Loss:  10.601498\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343695\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942647\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822858\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223904\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661392\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822856\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481707\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.2421255\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  4.458774\n",
            "Discriminator Loss:  10.900976\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044218\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942647\n",
            "Generator Loss:  4.7600427\n",
            "Discriminator Loss:  10.601498\n",
            "Generator Loss:  4.88055\n",
            "Discriminator Loss:  10.481708\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242124\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924425\n",
            "Generator Loss:  4.940804\n",
            "Discriminator Loss:  10.421811\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164006\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  4.8805504\n",
            "Discriminator Loss:  10.481708\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541603\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  4.7600427\n",
            "Discriminator Loss:  10.601498\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403588\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.061311\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  4.88055\n",
            "Discriminator Loss:  10.481707\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  4.3985205\n",
            "Discriminator Loss:  10.96087\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924424\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  4.6395354\n",
            "Discriminator Loss:  10.721289\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.182229\n",
            "Generator Loss:  5.3023257\n",
            "Discriminator Loss:  10.062438\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343695\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.42181\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822858\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822856\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822859\n",
            "Generator Loss:  4.5792813\n",
            "Discriminator Loss:  10.781184\n",
            "Generator Loss:  6.6279078\n",
            "Discriminator Loss:  8.744738\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361916\n",
            "Generator Loss:  4.519028\n",
            "Discriminator Loss:  10.84108\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  6.3868923\n",
            "Discriminator Loss:  8.984325\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223903\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  4.7600427\n",
            "Discriminator Loss:  10.601498\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  6.5676537\n",
            "Discriminator Loss:  8.804634\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.421812\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403588\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  4.7600427\n",
            "Discriminator Loss:  10.601498\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.04422\n",
            "Generator Loss:  5.8446097\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122335\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643173\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164006\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.2421255\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.94265\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523382\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  4.9408035\n",
            "Discriminator Loss:  10.42181\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223903\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942649\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463485\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583276\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.784355\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361916\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343694\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541603\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242126\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  4.579282\n",
            "Discriminator Loss:  10.781183\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403588\n",
            "Generator Loss:  4.88055\n",
            "Discriminator Loss:  10.481707\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.784355\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661392\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  4.5190277\n",
            "Discriminator Loss:  10.84108\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361916\n",
            "Generator Loss:  6.2061315\n",
            "Discriminator Loss:  9.164006\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822856\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403588\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  4.940804\n",
            "Discriminator Loss:  10.421811\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044216\n",
            "Generator Loss:  5.6035943\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.2420726\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583276\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223904\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583277\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  4.5190277\n",
            "Discriminator Loss:  10.941081\n",
            "Generator Loss:  4.7600427\n",
            "Discriminator Loss:  10.601498\n",
            "Generator Loss:  4.7600427\n",
            "Discriminator Loss:  10.601498\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  6.3868933\n",
            "Discriminator Loss:  8.98432\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942647\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  6.8086686\n",
            "Discriminator Loss:  8.565052\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  4.5190277\n",
            "Discriminator Loss:  10.84108\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343693\n",
            "Generator Loss:  4.6395354\n",
            "Discriminator Loss:  10.721289\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302022\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.182228\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463488\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343694\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062438\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343694\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463486\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942648\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.76296\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  6.266385\n",
            "Discriminator Loss:  9.104111\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.30202\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  4.7600427\n",
            "Discriminator Loss:  10.601498\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.98432\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044216\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  4.940804\n",
            "Discriminator Loss:  10.421812\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643169\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.965117\n",
            "Discriminator Loss:  9.403587\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762962\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361916\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361916\n",
            "Generator Loss:  6.3868923\n",
            "Discriminator Loss:  8.98432\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463485\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.0025425\n",
            "Generator Loss:  6.145878\n",
            "Discriminator Loss:  9.223902\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403588\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.182229\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.643171\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.904863\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  6.206132\n",
            "Discriminator Loss:  9.164007\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343696\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882753\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703068\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.3619175\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703067\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942658\n",
            "Generator Loss:  6.085624\n",
            "Discriminator Loss:  9.283797\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  6.6279078\n",
            "Discriminator Loss:  8.744739\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  6.2663856\n",
            "Discriminator Loss:  9.104113\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942647\n",
            "Generator Loss:  5.061311\n",
            "Discriminator Loss:  10.30202\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.82286\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523378\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361916\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.30202\n",
            "Generator Loss:  6.6279078\n",
            "Discriminator Loss:  8.744738\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541601\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.182229\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242125\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044215\n",
            "Generator Loss:  5.061311\n",
            "Discriminator Loss:  10.30202\n",
            "Generator Loss:  6.0253706\n",
            "Discriminator Loss:  9.343695\n",
            "Generator Loss:  4.940804\n",
            "Discriminator Loss:  10.42181\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822856\n",
            "Generator Loss:  5.181819\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.1223345\n",
            "Generator Loss:  4.5190277\n",
            "Discriminator Loss:  10.84108\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  6.326639\n",
            "Discriminator Loss:  9.044216\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.483087\n",
            "Discriminator Loss:  9.882751\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.242129\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924427\n",
            "Generator Loss:  5.6638484\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  4.760043\n",
            "Discriminator Loss:  10.601498\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.2421255\n",
            "Generator Loss:  5.1818185\n",
            "Discriminator Loss:  10.18223\n",
            "Generator Loss:  5.603595\n",
            "Discriminator Loss:  9.762961\n",
            "Generator Loss:  5.4830875\n",
            "Discriminator Loss:  9.882752\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541601\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.984321\n",
            "Generator Loss:  4.338267\n",
            "Discriminator Loss:  11.020766\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  5.302326\n",
            "Discriminator Loss:  10.062439\n",
            "Generator Loss:  5.0613112\n",
            "Discriminator Loss:  10.302021\n",
            "Generator Loss:  5.3625793\n",
            "Discriminator Loss:  10.002543\n",
            "Generator Loss:  5.9651165\n",
            "Discriminator Loss:  9.403589\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.984321\n",
            "Generator Loss:  5.724102\n",
            "Discriminator Loss:  9.64317\n",
            "Generator Loss:  4.940804\n",
            "Discriminator Loss:  10.421812\n",
            "Generator Loss:  5.663848\n",
            "Discriminator Loss:  9.703066\n",
            "Generator Loss:  6.386893\n",
            "Discriminator Loss:  8.98432\n",
            "Generator Loss:  5.9048634\n",
            "Discriminator Loss:  9.463484\n",
            "Generator Loss:  5.7843556\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.121565\n",
            "Discriminator Loss:  10.2421255\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  6.4471464\n",
            "Discriminator Loss:  8.924425\n",
            "Generator Loss:  5.36258\n",
            "Discriminator Loss:  10.002544\n",
            "Generator Loss:  5.242072\n",
            "Discriminator Loss:  10.122334\n",
            "Generator Loss:  5.5433407\n",
            "Discriminator Loss:  9.822857\n",
            "Generator Loss:  6.0856247\n",
            "Discriminator Loss:  9.283798\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.523379\n",
            "Generator Loss:  5.784356\n",
            "Discriminator Loss:  9.583275\n",
            "Generator Loss:  5.0010576\n",
            "Discriminator Loss:  10.361915\n",
            "Generator Loss:  4.699789\n",
            "Discriminator Loss:  10.661392\n",
            "Generator Loss:  5.8446093\n",
            "Discriminator Loss:  9.52338\n",
            "Generator Loss:  4.8202963\n",
            "Discriminator Loss:  10.541601\n",
            "Generator Loss:  5.4228334\n",
            "Discriminator Loss:  9.942647\n",
            "Generator Loss:  4.88055\n",
            "Discriminator Loss:  10.481708\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-83ec25c6b017>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-dec5f891a977>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data, epochs)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m       \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Uf4TIsoSWWaY",
        "outputId": "644ffd61-f7f8-47a8-b8d4-e72b7bc6fd85"
      },
      "source": [
        "test_image_noise = np.random.randn(1,100)\n",
        "generated_test_image = generator_model(test_image_noise)\n",
        "plt.imshow(tf.reshape(generated_test_image,(28,28)),cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7ecd9e5c10>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "bbYVYiF1dKp9",
        "outputId": "bfba1bf0-66ea-4364-9249-a77e05f7c760"
      },
      "source": [
        "random_image = np.random.randn(784)\n",
        "random_image = tf.reshape(random_image,(28,28))\n",
        "plt.imshow(random_image,cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7ecda09290>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STYXBxxSofFS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}