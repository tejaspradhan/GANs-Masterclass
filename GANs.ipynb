{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GANs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMJkTzwnccwuKZzpb5gKvHF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tejaspradhan/GANs-Masterclass/blob/main/GANs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsyyHiiuGTCR"
      },
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf \n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEOJcwQpGaYj"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "1Qxc4XyCGmlT",
        "outputId": "5ebc5200-31d8-4a43-e5d6-525d225265e2"
      },
      "source": [
        "plt.imshow(train_images[1], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-ead4bebc4893>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2649\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[0;32m-> 2651\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2652\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5624\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5626\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5627\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    697\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m    698\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0;32m--> 699\u001b[0;31m                             .format(self._A.shape))\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid shape (28, 28, 1) for image data"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kT3Y7UGBNY7W"
      },
      "source": [
        "# Normalization\n",
        "train_images= (train_images-127.5)/127.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "XzO1Up1KPJ1h",
        "outputId": "25cffbf6-a60f-4120-86f5-711a70e0500f"
      },
      "source": [
        "plt.imshow(train_images[0],cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-a21a7a5d3998>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2649\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[0;32m-> 2651\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2652\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5624\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5626\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5627\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    697\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m    698\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0;32m--> 699\u001b[0;31m                             .format(self._A.shape))\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid shape (28, 28, 1) for image data"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWwk7GYvHELY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7db3aa0-d6a6-4a6e-af0e-85b45e7256a7"
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aKfJS5zNS68",
        "outputId": "2b3c80fe-ca5a-46b9-8178-e805d99a722b"
      },
      "source": [
        "# Expanding dimensions\n",
        "train_images = train_images.reshape(train_images.shape[0],28,28,1)\n",
        "train_images.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWRsEG-POaDJ"
      },
      "source": [
        "# Defining parameters\n",
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_AmY1jEOc2H"
      },
      "source": [
        "# Batchwise shuffling of the dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G94T_C2oPqRh"
      },
      "source": [
        "## Discriminator "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "In1NjbwEPv8o"
      },
      "source": [
        "def discriminator():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Conv2D(7,(3,3),padding='same',input_shape=(28,28,1)))\n",
        "  model.add(tf.keras.layers.Conv2D(7,(3,3),padding='same'))\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(50,activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(1))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qB8TyvTiQifM"
      },
      "source": [
        "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHz4O2ITQsoK"
      },
      "source": [
        "# loss function for the discriminator \n",
        "def discriminator_loss(real_predictions, fake_predictions):\n",
        "  real_predictions = tf.sigmoid(real_predictions)\n",
        "  fake_predictions = tf.sigmoid(fake_predictions)\n",
        "  real_loss = tf.keras.losses.binary_crossentropy(tf.ones_like(real_predictions), real_predictions)\n",
        "  fake_loss = tf.keras.losses.binary_crossentropy(tf.zeros_like(fake_predictions),fake_predictions)\n",
        "  if real_loss.shape == fake_loss.shape:\n",
        "    return real_loss+fake_loss\n",
        "  else:\n",
        "    return fake_loss+0.1\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqNHc6mPQ20z"
      },
      "source": [
        "## Generator "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBz-OGsuSqbG"
      },
      "source": [
        "def generator():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(7*7*256,input_shape =(100,)))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Dense(7*7*256))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Reshape( (7,7,256) ))\n",
        "  model.add(tf.keras.layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same'))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same'))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same'))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrtQfiFsU9MB"
      },
      "source": [
        "def generator_loss(fake_predictions):\n",
        "  fake_predictions = tf.sigmoid(fake_predictions)\n",
        "  fake_loss = tf.keras.losses.binary_crossentropy(tf.ones_like(fake_predictions),fake_predictions)\n",
        "  return fake_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbZRwnYOU_p5"
      },
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWPIMCR5XRhc"
      },
      "source": [
        "generator_model= generator()\n",
        "discriminator_model = discriminator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2h3XQDzVT_q"
      },
      "source": [
        "## Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsaiHuhpVe6l"
      },
      "source": [
        "def train(data, epochs):\n",
        "  for i in range(epochs):\n",
        "    for images in data:\n",
        "      images = tf.cast(images,tf.dtypes.float32)\n",
        "      train_step(images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BqRJHuVVwLR"
      },
      "source": [
        "def train_step(images):\n",
        "  noise = np.random.randn(BATCH_SIZE, 100).astype('float32')\n",
        "  # batchwise training \n",
        "  with tf.GradientTape() as generator_tape, tf.GradientTape() as discriminator_tape:\n",
        "        # Create fake images \n",
        "        generated_images = generator_model(noise)\n",
        "        # Pass fake images through the discriminator \n",
        "        generator_output = discriminator_model(generated_images)\n",
        "        # Pass real images through the discriminator \n",
        "        real_output = discriminator_model(images)\n",
        "\n",
        "        # calculate individual losses\n",
        "        gen_loss = generator_loss(generator_output)\n",
        "        disc_loss = discriminator_loss(real_output, generator_output)\n",
        "        \n",
        "        # Calculate gradients of loss functions\n",
        "        generator_gradients= generator_tape.gradient(gen_loss,generator_model.trainable_variables)\n",
        "        discriminator_gradients = discriminator_tape.gradient(disc_loss, discriminator_model.trainable_variables)\n",
        "        \n",
        "        # Optimise\n",
        "        generator_optimizer.apply_gradients(zip(generator_gradients, generator_model.trainable_variables))\n",
        "        discriminator_optimizer.apply_gradients(zip(discriminator_gradients, discriminator_model.trainable_variables))\n",
        "        \n",
        "        print(\"Generator Loss: \",np.mean(gen_loss))\n",
        "        print(\"Discriminator Loss: \",np.mean(disc_loss))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xGbk6W1FWT_Z",
        "outputId": "373fa649-49ba-4de8-d606-8db121c8ae48"
      },
      "source": [
        "train(train_dataset,100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177903\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95841414\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0782012\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578908\n",
            "Generator Loss:  13.85835\n",
            "Discriminator Loss:  1.5573524\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578803\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0183064\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979821\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578955\n",
            "Generator Loss:  14.701902\n",
            "Discriminator Loss:  0.7188223\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3777461\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3178117\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95841265\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0183175\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380867\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380897\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380901\n",
            "Generator Loss:  14.460886\n",
            "Discriminator Loss:  0.9584141\n",
            "Generator Loss:  13.737843\n",
            "Discriminator Loss:  1.6772058\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177805\n",
            "Generator Loss:  14.400634\n",
            "Discriminator Loss:  1.0182948\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0782075\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0782062\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9584269\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974716\n",
            "Generator Loss:  14.641648\n",
            "Discriminator Loss:  0.7787153\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177717\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8386364\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578967\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9584097\n",
            "Generator Loss:  14.641648\n",
            "Discriminator Loss:  0.77872306\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781965\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0782102\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578819\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776693\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979871\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776813\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8985087\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375675\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182998\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375952\n",
            "Generator Loss:  14.400634\n",
            "Discriminator Loss:  1.0183153\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95841384\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781941\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.958428\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8386206\n",
            "Generator Loss:  13.798096\n",
            "Discriminator Loss:  1.6172788\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1381003\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8386042\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578876\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9584267\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979886\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776846\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1980028\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781872\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380935\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380961\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9584302\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380885\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8386404\n",
            "Generator Loss:  15.00317\n",
            "Discriminator Loss:  0.4193389\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177828\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578831\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0183108\n",
            "Generator Loss:  14.039112\n",
            "Discriminator Loss:  1.3776711\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1980001\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380866\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8386276\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776736\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177824\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.198025\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.198009\n",
            "Generator Loss:  14.641648\n",
            "Discriminator Loss:  0.7787267\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89850754\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95841324\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.437567\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.83862096\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8985342\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380957\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979934\n",
            "Generator Loss:  13.978858\n",
            "Discriminator Loss:  1.4375741\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89851296\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375625\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.257902\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.898509\n",
            "Generator Loss:  14.039112\n",
            "Discriminator Loss:  1.3776724\n",
            "Generator Loss:  13.798096\n",
            "Discriminator Loss:  1.6172451\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89851683\n",
            "Generator Loss:  14.822409\n",
            "Discriminator Loss:  0.59904134\n",
            "Generator Loss:  13.617335\n",
            "Discriminator Loss:  1.7969375\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781913\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95840585\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380911\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380882\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8985065\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380984\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.138092\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.078195\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781931\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89850783\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974709\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380882\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979995\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182968\n",
            "Generator Loss:  13.677589\n",
            "Discriminator Loss:  1.7370403\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.497458\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776655\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.83861554\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979845\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1980027\n",
            "Generator Loss:  13.858351\n",
            "Discriminator Loss:  1.55736\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177693\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.138092\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0782015\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89850384\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177887\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583976\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182987\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380955\n",
            "Generator Loss:  14.400634\n",
            "Discriminator Loss:  1.0182958\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979817\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177783\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776822\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380967\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974585\n",
            "Generator Loss:  14.460888\n",
            "Discriminator Loss:  0.95840234\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.138093\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776835\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781915\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0183171\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8985091\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578809\n",
            "Generator Loss:  14.641648\n",
            "Discriminator Loss:  0.7787124\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380908\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89849883\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380901\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578952\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380799\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177761\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979825\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776795\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979818\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177795\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979828\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375701\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974597\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776731\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776691\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578809\n",
            "Generator Loss:  14.701902\n",
            "Discriminator Loss:  0.71883124\n",
            "Generator Loss:  14.762156\n",
            "Discriminator Loss:  0.6589206\n",
            "Generator Loss:  14.460886\n",
            "Discriminator Loss:  0.9584198\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177927\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182946\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578735\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380911\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979884\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0183158\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95839745\n",
            "Generator Loss:  14.701901\n",
            "Discriminator Loss:  0.71884006\n",
            "Generator Loss:  14.641647\n",
            "Discriminator Loss:  0.7787081\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380928\n",
            "Generator Loss:  14.099364\n",
            "Discriminator Loss:  1.317821\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776798\n",
            "Generator Loss:  13.978858\n",
            "Discriminator Loss:  1.4375916\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0782206\n",
            "Generator Loss:  14.400634\n",
            "Discriminator Loss:  1.018286\n",
            "Generator Loss:  14.039112\n",
            "Discriminator Loss:  1.3776692\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380829\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583981\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8386162\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979761\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578756\n",
            "Generator Loss:  13.617335\n",
            "Discriminator Loss:  1.7969365\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776623\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1381036\n",
            "Generator Loss:  13.858351\n",
            "Discriminator Loss:  1.557353\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979849\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0183122\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375696\n",
            "Generator Loss:  14.03911\n",
            "Discriminator Loss:  1.3776919\n",
            "Generator Loss:  13.617335\n",
            "Discriminator Loss:  1.7969273\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.83860713\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0782\n",
            "Generator Loss:  14.400634\n",
            "Discriminator Loss:  1.0182911\n",
            "Generator Loss:  13.85835\n",
            "Discriminator Loss:  1.5573727\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781857\n",
            "Generator Loss:  14.039112\n",
            "Discriminator Loss:  1.3776685\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380832\n",
            "Generator Loss:  14.03911\n",
            "Discriminator Loss:  1.3776643\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578785\n",
            "Generator Loss:  13.978858\n",
            "Discriminator Loss:  1.4375576\n",
            "Generator Loss:  14.641647\n",
            "Discriminator Loss:  0.7787157\n",
            "Generator Loss:  14.762156\n",
            "Discriminator Loss:  0.6589607\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8985059\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182936\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776791\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1381048\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177767\n",
            "Generator Loss:  14.03911\n",
            "Discriminator Loss:  1.3776795\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380856\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.83861685\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380821\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979823\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182854\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182929\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578714\n",
            "Generator Loss:  13.858351\n",
            "Discriminator Loss:  1.5573739\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781808\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8985018\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979824\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8386135\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8984997\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9584025\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781834\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979849\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979927\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781983\n",
            "Generator Loss:  14.099364\n",
            "Discriminator Loss:  1.3177831\n",
            "Generator Loss:  14.762156\n",
            "Discriminator Loss:  0.658932\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781919\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0183005\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182934\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0183005\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979768\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375651\n",
            "Generator Loss:  14.460886\n",
            "Discriminator Loss:  0.95840216\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182912\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380811\n",
            "Generator Loss:  14.039112\n",
            "Discriminator Loss:  1.3776605\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380794\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.83861375\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375659\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182891\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.99843204\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.377668\n",
            "Generator Loss:  13.85835\n",
            "Discriminator Loss:  1.5573457\n",
            "Generator Loss:  13.798097\n",
            "Discriminator Loss:  1.6172483\n",
            "Generator Loss:  14.701901\n",
            "Discriminator Loss:  0.71882504\n",
            "Generator Loss:  14.03911\n",
            "Discriminator Loss:  1.37767\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177627\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380773\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9584059\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979833\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182892\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583921\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781868\n",
            "Generator Loss:  14.641648\n",
            "Discriminator Loss:  0.77870643\n",
            "Generator Loss:  13.677588\n",
            "Discriminator Loss:  1.7370403\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781889\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781825\n",
            "Generator Loss:  14.762156\n",
            "Discriminator Loss:  0.6589366\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380836\n",
            "Generator Loss:  14.099364\n",
            "Discriminator Loss:  1.3177747\n",
            "Generator Loss:  14.641647\n",
            "Discriminator Loss:  0.778706\n",
            "Generator Loss:  13.075052\n",
            "Discriminator Loss:  2.3359914\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177722\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.25788\n",
            "Generator Loss:  14.03911\n",
            "Discriminator Loss:  1.3776627\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182889\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9584005\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974607\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979818\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979944\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380813\n",
            "Generator Loss:  14.701902\n",
            "Discriminator Loss:  0.71881384\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979828\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781858\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8386115\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89849865\n",
            "Generator Loss:  13.737843\n",
            "Discriminator Loss:  1.6771402\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979879\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.078196\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781915\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781901\n",
            "Generator Loss:  14.762156\n",
            "Discriminator Loss:  0.658934\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95839334\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95840454\n",
            "Generator Loss:  14.099364\n",
            "Discriminator Loss:  1.3177633\n",
            "Generator Loss:  13.737843\n",
            "Discriminator Loss:  1.67715\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.898502\n",
            "Generator Loss:  14.641647\n",
            "Discriminator Loss:  0.7787148\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.197978\n",
            "Generator Loss:  14.641648\n",
            "Discriminator Loss:  0.7787039\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979831\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776699\n",
            "Generator Loss:  13.737843\n",
            "Discriminator Loss:  1.6771369\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8984988\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.197978\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578697\n",
            "Generator Loss:  14.099364\n",
            "Discriminator Loss:  1.3177919\n",
            "Generator Loss:  14.03911\n",
            "Discriminator Loss:  1.3776784\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182886\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380949\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578661\n",
            "Generator Loss:  13.858351\n",
            "Discriminator Loss:  1.557349\n",
            "Generator Loss:  13.737843\n",
            "Discriminator Loss:  1.6771405\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979837\n",
            "Generator Loss:  14.099364\n",
            "Discriminator Loss:  1.3177656\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578683\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776891\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380869\n",
            "Generator Loss:  14.701902\n",
            "Discriminator Loss:  0.71881735\n",
            "Generator Loss:  14.039112\n",
            "Discriminator Loss:  1.3776639\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578714\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8985075\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781949\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380783\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8985071\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177552\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974855\n",
            "Generator Loss:  14.400634\n",
            "Discriminator Loss:  1.0182993\n",
            "Generator Loss:  14.099364\n",
            "Discriminator Loss:  1.317765\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583994\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583954\n",
            "Generator Loss:  14.882664\n",
            "Discriminator Loss:  0.5391823\n",
            "Generator Loss:  14.400634\n",
            "Discriminator Loss:  1.0182831\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89850336\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1381207\n",
            "Generator Loss:  14.03911\n",
            "Discriminator Loss:  1.3776555\n",
            "Generator Loss:  14.641648\n",
            "Discriminator Loss:  0.77870774\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781839\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974668\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182853\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177598\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182846\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380837\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979829\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776696\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979725\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89850163\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375715\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375577\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979775\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776658\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177634\n",
            "Generator Loss:  13.617335\n",
            "Discriminator Loss:  1.7969334\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578688\n",
            "Generator Loss:  14.641648\n",
            "Discriminator Loss:  0.7787024\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8386082\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781885\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.257863\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578707\n",
            "Generator Loss:  14.701902\n",
            "Discriminator Loss:  0.71880794\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89850914\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.83860004\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8985059\n",
            "Generator Loss:  14.52114\n",
            "Discriminator Loss:  0.8984944\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375542\n",
            "Generator Loss:  14.822409\n",
            "Discriminator Loss:  0.5990269\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375541\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781817\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177671\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578673\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776611\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979734\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578725\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974532\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.83860517\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776591\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979868\n",
            "Generator Loss:  14.099364\n",
            "Discriminator Loss:  1.3177607\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380762\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776506\n",
            "Generator Loss:  14.400634\n",
            "Discriminator Loss:  1.0183145\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375603\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182846\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380725\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89849854\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95838547\n",
            "Generator Loss:  14.762156\n",
            "Discriminator Loss:  0.65891314\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380788\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375776\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.197969\n",
            "Generator Loss:  14.03911\n",
            "Discriminator Loss:  1.3776652\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380856\n",
            "Generator Loss:  14.099364\n",
            "Discriminator Loss:  1.3177824\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.83859396\n",
            "Generator Loss:  13.557082\n",
            "Discriminator Loss:  1.8568215\n",
            "Generator Loss:  14.099364\n",
            "Discriminator Loss:  1.3177752\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177752\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380913\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583936\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578709\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380847\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1381066\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979808\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578721\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.377658\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8386062\n",
            "Generator Loss:  14.641647\n",
            "Discriminator Loss:  0.7787068\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578869\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781875\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776686\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.838596\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182896\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182902\n",
            "Generator Loss:  13.737843\n",
            "Discriminator Loss:  1.6771436\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375584\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578673\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8984933\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182884\n",
            "Generator Loss:  14.099364\n",
            "Discriminator Loss:  1.3177762\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177594\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9584063\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375513\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380856\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95839715\n",
            "Generator Loss:  14.340379\n",
            "Discriminator Loss:  1.0782003\n",
            "Generator Loss:  13.85835\n",
            "Discriminator Loss:  1.5573409\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.018283\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182793\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8984916\n",
            "Generator Loss:  13.858351\n",
            "Discriminator Loss:  1.5573485\n",
            "Generator Loss:  14.460888\n",
            "Discriminator Loss:  0.95839936\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776898\n",
            "Generator Loss:  14.52114\n",
            "Discriminator Loss:  0.8984945\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578646\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781744\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578652\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8385986\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380886\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8385931\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979666\n",
            "Generator Loss:  14.099364\n",
            "Discriminator Loss:  1.3177565\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.377678\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.377659\n",
            "Generator Loss:  14.03911\n",
            "Discriminator Loss:  1.3776578\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8385942\n",
            "Generator Loss:  13.798097\n",
            "Discriminator Loss:  1.6172521\n",
            "Generator Loss:  14.641648\n",
            "Discriminator Loss:  0.77870035\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776578\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781792\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177602\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979744\n",
            "Generator Loss:  14.82241\n",
            "Discriminator Loss:  0.5990242\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578814\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.01828\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375496\n",
            "Generator Loss:  14.762156\n",
            "Discriminator Loss:  0.65891373\n",
            "Generator Loss:  13.798096\n",
            "Discriminator Loss:  1.6172514\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380857\n",
            "Generator Loss:  13.737843\n",
            "Discriminator Loss:  1.6771488\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89849615\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182929\n",
            "Generator Loss:  14.400634\n",
            "Discriminator Loss:  1.0182858\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776516\n",
            "Generator Loss:  14.701901\n",
            "Discriminator Loss:  0.7188054\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375556\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979728\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578778\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578613\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979725\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177681\n",
            "Generator Loss:  14.641647\n",
            "Discriminator Loss:  0.77870035\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182831\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380696\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578661\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781804\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1381013\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974505\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979655\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781777\n",
            "Generator Loss:  14.641647\n",
            "Discriminator Loss:  0.77871156\n",
            "Generator Loss:  13.978858\n",
            "Discriminator Loss:  1.4375534\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95838547\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979766\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979716\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781736\n",
            "Generator Loss:  14.400634\n",
            "Discriminator Loss:  1.1182228\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8385904\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.377664\n",
            "Generator Loss:  14.460886\n",
            "Discriminator Loss:  0.9583823\n",
            "Generator Loss:  13.737843\n",
            "Discriminator Loss:  1.6771326\n",
            "Generator Loss:  14.822409\n",
            "Discriminator Loss:  0.5990157\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177593\n",
            "Generator Loss:  15.00317\n",
            "Discriminator Loss:  0.4193287\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182817\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8385902\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8984899\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8386047\n",
            "Generator Loss:  14.400634\n",
            "Discriminator Loss:  1.0182784\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979694\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8984871\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776894\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375579\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89848983\n",
            "Generator Loss:  13.737843\n",
            "Discriminator Loss:  1.6771426\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979699\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380706\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182812\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.838596\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375517\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578642\n",
            "Generator Loss:  14.099364\n",
            "Discriminator Loss:  1.3177571\n",
            "Generator Loss:  14.641647\n",
            "Discriminator Loss:  0.7787109\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.01829\n",
            "Generator Loss:  14.701902\n",
            "Discriminator Loss:  0.7188022\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182815\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8984878\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.138071\n",
            "Generator Loss:  13.798097\n",
            "Discriminator Loss:  1.6172493\n",
            "Generator Loss:  14.762156\n",
            "Discriminator Loss:  0.65892154\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583824\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.257864\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89848787\n",
            "Generator Loss:  14.701902\n",
            "Discriminator Loss:  0.7187999\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89848447\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776946\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89849055\n",
            "Generator Loss:  14.099364\n",
            "Discriminator Loss:  1.3177578\n",
            "Generator Loss:  14.039112\n",
            "Discriminator Loss:  1.3776622\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979669\n",
            "Generator Loss:  13.737843\n",
            "Discriminator Loss:  1.677152\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380708\n",
            "Generator Loss:  13.798096\n",
            "Discriminator Loss:  1.6172287\n",
            "Generator Loss:  14.460888\n",
            "Discriminator Loss:  0.9583923\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781828\n",
            "Generator Loss:  14.03911\n",
            "Discriminator Loss:  1.3776532\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578745\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974552\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974384\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.83861244\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182863\n",
            "Generator Loss:  14.882664\n",
            "Discriminator Loss:  0.5391263\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380672\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95839643\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380625\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8985024\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781721\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979647\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578595\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578808\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583818\n",
            "Generator Loss:  14.03911\n",
            "Discriminator Loss:  1.3776591\n",
            "Generator Loss:  14.460888\n",
            "Discriminator Loss:  0.9583819\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979707\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182861\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182757\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380835\n",
            "Generator Loss:  13.737843\n",
            "Discriminator Loss:  1.6771286\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.078181\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781791\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.138088\n",
            "Generator Loss:  14.52114\n",
            "Discriminator Loss:  0.8984871\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.197968\n",
            "Generator Loss:  13.617335\n",
            "Discriminator Loss:  1.7969297\n",
            "Generator Loss:  14.099364\n",
            "Discriminator Loss:  1.317752\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182762\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974389\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.83859754\n",
            "Generator Loss:  14.641648\n",
            "Discriminator Loss:  0.77870744\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776517\n",
            "Generator Loss:  13.85835\n",
            "Discriminator Loss:  1.5573381\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578645\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375492\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979665\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974425\n",
            "Generator Loss:  14.400634\n",
            "Discriminator Loss:  1.018285\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.377656\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776486\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375513\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.018284\n",
            "Generator Loss:  14.460888\n",
            "Discriminator Loss:  0.9583838\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781822\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95838463\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.078185\n",
            "Generator Loss:  14.701902\n",
            "Discriminator Loss:  0.7188023\n",
            "Generator Loss:  14.641647\n",
            "Discriminator Loss:  0.77870584\n",
            "Generator Loss:  14.942917\n",
            "Discriminator Loss:  0.47922254\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0183294\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8984903\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375459\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8984929\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781809\n",
            "Generator Loss:  14.039112\n",
            "Discriminator Loss:  1.3776481\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182824\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375455\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380732\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375434\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177559\n",
            "Generator Loss:  13.858351\n",
            "Discriminator Loss:  1.5573374\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974512\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781885\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578584\n",
            "Generator Loss:  13.978858\n",
            "Discriminator Loss:  1.4375408\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.138071\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578591\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974408\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979616\n",
            "Generator Loss:  14.460888\n",
            "Discriminator Loss:  0.9583775\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375517\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.317751\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95838594\n",
            "Generator Loss:  13.858351\n",
            "Discriminator Loss:  1.5573385\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.078178\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182955\n",
            "Generator Loss:  14.52114\n",
            "Discriminator Loss:  0.89848614\n",
            "Generator Loss:  14.460888\n",
            "Discriminator Loss:  0.95838696\n",
            "Generator Loss:  13.737843\n",
            "Discriminator Loss:  1.6771321\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776481\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380689\n",
            "Generator Loss:  13.677589\n",
            "Discriminator Loss:  1.7370336\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.078172\n",
            "Generator Loss:  13.798096\n",
            "Discriminator Loss:  1.6172299\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781811\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.018289\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.497438\n",
            "Generator Loss:  13.798096\n",
            "Discriminator Loss:  1.617234\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781753\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578614\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375414\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380682\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375505\n",
            "Generator Loss:  14.641649\n",
            "Discriminator Loss:  0.7786974\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.83858895\n",
            "Generator Loss:  13.85835\n",
            "Discriminator Loss:  1.5573392\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578633\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578561\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375485\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979594\n",
            "Generator Loss:  14.099364\n",
            "Discriminator Loss:  1.3177632\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8385956\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375393\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974525\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89849246\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.317764\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95839494\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974365\n",
            "Generator Loss:  13.737843\n",
            "Discriminator Loss:  1.6771307\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89848894\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578641\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380723\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182775\n",
            "Generator Loss:  13.436574\n",
            "Discriminator Loss:  1.9766097\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182875\n",
            "Generator Loss:  14.762156\n",
            "Discriminator Loss:  0.65892065\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8984829\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974364\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781814\n",
            "Generator Loss:  14.762156\n",
            "Discriminator Loss:  0.65890956\n",
            "Generator Loss:  14.762156\n",
            "Discriminator Loss:  0.658902\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182729\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89849323\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578591\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380658\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578654\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.958381\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.078176\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95838845\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177608\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979592\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177507\n",
            "Generator Loss:  14.82241\n",
            "Discriminator Loss:  0.5990069\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979673\n",
            "Generator Loss:  14.400634\n",
            "Discriminator Loss:  1.018295\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177798\n",
            "Generator Loss:  14.701901\n",
            "Discriminator Loss:  0.7187973\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380711\n",
            "Generator Loss:  13.798096\n",
            "Discriminator Loss:  1.6172311\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781739\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.138068\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781677\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776537\n",
            "Generator Loss:  14.641647\n",
            "Discriminator Loss:  0.77869403\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8385954\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.018274\n",
            "Generator Loss:  14.099364\n",
            "Discriminator Loss:  1.3177545\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.138076\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.138068\n",
            "Generator Loss:  14.641648\n",
            "Discriminator Loss:  0.7786972\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578638\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781779\n",
            "Generator Loss:  13.858351\n",
            "Discriminator Loss:  1.5573328\n",
            "Generator Loss:  13.85835\n",
            "Discriminator Loss:  1.5573561\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781881\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979606\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781732\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.018283\n",
            "Generator Loss:  13.798097\n",
            "Discriminator Loss:  1.617242\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979651\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578629\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95838475\n",
            "Generator Loss:  14.701902\n",
            "Discriminator Loss:  0.7188099\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781715\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8984802\n",
            "Generator Loss:  14.039112\n",
            "Discriminator Loss:  1.3776431\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974571\n",
            "Generator Loss:  14.03911\n",
            "Discriminator Loss:  1.3776523\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8385937\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182728\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177648\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375415\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979609\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583773\n",
            "Generator Loss:  14.099364\n",
            "Discriminator Loss:  1.3177576\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583736\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583837\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8385986\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583744\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578583\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8385972\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380674\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375458\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.1781183\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8984884\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182711\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.197963\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177505\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8385873\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.437547\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380664\n",
            "Generator Loss:  13.737843\n",
            "Discriminator Loss:  1.6771241\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182786\n",
            "Generator Loss:  14.641648\n",
            "Discriminator Loss:  0.7786858\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.197958\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177519\n",
            "Generator Loss:  14.581395\n",
            "Discriminator Loss:  0.83859324\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177567\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375452\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578545\n",
            "Generator Loss:  14.942917\n",
            "Discriminator Loss:  0.4792376\n",
            "Generator Loss:  13.858351\n",
            "Discriminator Loss:  1.5573336\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578564\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177612\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380656\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781746\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.257856\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979617\n",
            "Generator Loss:  14.762156\n",
            "Discriminator Loss:  0.65890676\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776485\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.018283\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781869\n",
            "Generator Loss:  14.641647\n",
            "Discriminator Loss:  0.7787124\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979635\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380687\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380622\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95838565\n",
            "Generator Loss:  14.400634\n",
            "Discriminator Loss:  1.0182774\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578543\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380786\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177562\n",
            "Generator Loss:  14.03911\n",
            "Discriminator Loss:  1.3776473\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380699\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177491\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375418\n",
            "Generator Loss:  14.460886\n",
            "Discriminator Loss:  0.9583808\n",
            "Generator Loss:  13.978858\n",
            "Discriminator Loss:  1.4375393\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375415\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.078166\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979582\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583806\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182738\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776424\n",
            "Generator Loss:  14.03911\n",
            "Discriminator Loss:  1.3776438\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89848197\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781642\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177494\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776535\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974322\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380616\n",
            "Generator Loss:  14.460888\n",
            "Discriminator Loss:  0.9583738\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781641\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8385844\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8385888\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979568\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781668\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781659\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177539\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8984782\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375439\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781612\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182695\n",
            "Generator Loss:  14.039112\n",
            "Discriminator Loss:  1.3776399\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177584\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781691\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95837533\n",
            "Generator Loss:  14.701901\n",
            "Discriminator Loss:  0.71879774\n",
            "Generator Loss:  13.798096\n",
            "Discriminator Loss:  1.617227\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182786\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578566\n",
            "Generator Loss:  14.460886\n",
            "Discriminator Loss:  0.95837533\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979625\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.138064\n",
            "Generator Loss:  14.400634\n",
            "Discriminator Loss:  1.0182704\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.018271\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.83858407\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781664\n",
            "Generator Loss:  14.822409\n",
            "Discriminator Loss:  0.5990157\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177536\n",
            "Generator Loss:  13.677589\n",
            "Discriminator Loss:  1.7370116\n",
            "Generator Loss:  14.701902\n",
            "Discriminator Loss:  0.7187969\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974383\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.197958\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979656\n",
            "Generator Loss:  14.219873\n",
            "Discriminator Loss:  1.1979562\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.197953\n",
            "Generator Loss:  14.701902\n",
            "Discriminator Loss:  0.7188034\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578712\n",
            "Generator Loss:  14.641647\n",
            "Discriminator Loss:  0.7786934\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.257853\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375404\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.898481\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.078172\n",
            "Generator Loss:  14.52114\n",
            "Discriminator Loss:  0.8984892\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8984885\n",
            "Generator Loss:  14.039112\n",
            "Discriminator Loss:  1.3776486\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979566\n",
            "Generator Loss:  13.85835\n",
            "Discriminator Loss:  1.5573283\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177724\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979575\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578584\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.078176\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.83858794\n",
            "Generator Loss:  14.701902\n",
            "Discriminator Loss:  0.71879447\n",
            "Generator Loss:  14.701902\n",
            "Discriminator Loss:  0.7187983\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380662\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781766\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95838135\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380703\n",
            "Generator Loss:  13.677589\n",
            "Discriminator Loss:  1.737017\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380706\n",
            "Generator Loss:  14.280125\n",
            "Discriminator Loss:  1.1380632\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380681\n",
            "Generator Loss:  14.641648\n",
            "Discriminator Loss:  0.7786856\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380658\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974357\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578492\n",
            "Generator Loss:  14.641648\n",
            "Discriminator Loss:  0.77870595\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.138061\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781641\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89847744\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979549\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.958372\n",
            "Generator Loss:  14.641647\n",
            "Discriminator Loss:  0.77869296\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781764\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979821\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583851\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583704\n",
            "Generator Loss:  14.219873\n",
            "Discriminator Loss:  1.1979558\n",
            "Generator Loss:  14.099364\n",
            "Discriminator Loss:  1.3177598\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578517\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182818\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.078171\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583707\n",
            "Generator Loss:  14.882664\n",
            "Discriminator Loss:  0.5391037\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578499\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781667\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.83857995\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182753\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583752\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182719\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979563\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979628\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.83857894\n",
            "Generator Loss:  14.942917\n",
            "Discriminator Loss:  0.47921038\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380576\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182676\n",
            "Generator Loss:  14.701902\n",
            "Discriminator Loss:  0.7187983\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182681\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182738\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8984752\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380609\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182776\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979578\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776515\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380595\n",
            "Generator Loss:  14.340379\n",
            "Discriminator Loss:  1.0781701\n",
            "Generator Loss:  13.798096\n",
            "Discriminator Loss:  1.6172273\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182675\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781662\n",
            "Generator Loss:  14.400634\n",
            "Discriminator Loss:  1.0182699\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781661\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979609\n",
            "Generator Loss:  13.798096\n",
            "Discriminator Loss:  1.6172225\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.83858114\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0183033\n",
            "Generator Loss:  13.978858\n",
            "Discriminator Loss:  1.4375534\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8984847\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380649\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8385833\n",
            "Generator Loss:  13.85835\n",
            "Discriminator Loss:  1.5573311\n",
            "Generator Loss:  14.400634\n",
            "Discriminator Loss:  1.0182749\n",
            "Generator Loss:  14.641648\n",
            "Discriminator Loss:  0.7786861\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182676\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.197959\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781679\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979511\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8984796\n",
            "Generator Loss:  13.858351\n",
            "Discriminator Loss:  1.5573417\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781633\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380615\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182756\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974315\n",
            "Generator Loss:  14.52114\n",
            "Discriminator Loss:  0.89847916\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182694\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578514\n",
            "Generator Loss:  13.858351\n",
            "Discriminator Loss:  1.5573276\n",
            "Generator Loss:  14.039112\n",
            "Discriminator Loss:  1.3776588\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979619\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781674\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8984786\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578522\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.497441\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.377641\n",
            "Generator Loss:  13.737843\n",
            "Discriminator Loss:  1.6771246\n",
            "Generator Loss:  14.099364\n",
            "Discriminator Loss:  1.3177613\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.138066\n",
            "Generator Loss:  13.798097\n",
            "Discriminator Loss:  1.6172216\n",
            "Generator Loss:  13.978858\n",
            "Discriminator Loss:  1.4375384\n",
            "Generator Loss:  14.03911\n",
            "Discriminator Loss:  1.3776387\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177435\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182676\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182679\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979529\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89848053\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380577\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380622\n",
            "Generator Loss:  14.762156\n",
            "Discriminator Loss:  0.6588987\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.437537\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776491\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182753\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182637\n",
            "Generator Loss:  14.400634\n",
            "Discriminator Loss:  1.0182691\n",
            "Generator Loss:  14.882664\n",
            "Discriminator Loss:  0.5391039\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177439\n",
            "Generator Loss:  13.617336\n",
            "Discriminator Loss:  1.7969106\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380833\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.197959\n",
            "Generator Loss:  13.85835\n",
            "Discriminator Loss:  1.557327\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578509\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375391\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89847696\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182709\n",
            "Generator Loss:  14.641648\n",
            "Discriminator Loss:  0.7786876\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979654\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583723\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979601\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.197955\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.118223\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781689\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979544\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380614\n",
            "Generator Loss:  14.400634\n",
            "Discriminator Loss:  1.0182731\n",
            "Generator Loss:  14.581395\n",
            "Discriminator Loss:  0.8385818\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182755\n",
            "Generator Loss:  13.677589\n",
            "Discriminator Loss:  1.7370138\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781771\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.257853\n",
            "Generator Loss:  13.858351\n",
            "Discriminator Loss:  1.5573256\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974339\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578493\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182767\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974496\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380657\n",
            "Generator Loss:  14.400634\n",
            "Discriminator Loss:  1.018264\n",
            "Generator Loss:  13.737843\n",
            "Discriminator Loss:  1.6771144\n",
            "Generator Loss:  14.460886\n",
            "Discriminator Loss:  0.9583683\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.018267\n",
            "Generator Loss:  14.400634\n",
            "Discriminator Loss:  1.0182662\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974308\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182645\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89847827\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979584\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781617\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182838\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182661\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177545\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177502\n",
            "Generator Loss:  14.701902\n",
            "Discriminator Loss:  0.71878886\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177419\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95838684\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776381\n",
            "Generator Loss:  14.52114\n",
            "Discriminator Loss:  0.8984751\n",
            "Generator Loss:  13.557081\n",
            "Discriminator Loss:  1.8568046\n",
            "Generator Loss:  14.52114\n",
            "Discriminator Loss:  0.89847505\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.138062\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380836\n",
            "Generator Loss:  13.858351\n",
            "Discriminator Loss:  1.5573276\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979532\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.078161\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375358\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979613\n",
            "Generator Loss:  14.460886\n",
            "Discriminator Loss:  0.95837533\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583692\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375337\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8984804\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380556\n",
            "Generator Loss:  13.677589\n",
            "Discriminator Loss:  1.7370169\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.83858204\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578462\n",
            "Generator Loss:  14.641648\n",
            "Discriminator Loss:  0.7786863\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177439\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95836866\n",
            "Generator Loss:  13.798096\n",
            "Discriminator Loss:  1.6172256\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95836735\n",
            "Generator Loss:  14.400634\n",
            "Discriminator Loss:  1.0182817\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380551\n",
            "Generator Loss:  13.858351\n",
            "Discriminator Loss:  1.5573235\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979512\n",
            "Generator Loss:  13.677589\n",
            "Discriminator Loss:  1.7370167\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583736\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578502\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.83858097\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979506\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.078161\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.257843\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578495\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578456\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375384\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380645\n",
            "Generator Loss:  13.798096\n",
            "Discriminator Loss:  1.6172241\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781617\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177428\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979522\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182712\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979477\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177437\n",
            "Generator Loss:  14.099364\n",
            "Discriminator Loss:  1.3177444\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177426\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974325\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.078156\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578481\n",
            "Generator Loss:  14.400634\n",
            "Discriminator Loss:  1.0182648\n",
            "Generator Loss:  14.641648\n",
            "Discriminator Loss:  0.7786815\n",
            "Generator Loss:  14.460886\n",
            "Discriminator Loss:  0.9583683\n",
            "Generator Loss:  14.099364\n",
            "Discriminator Loss:  1.31774\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.138068\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89847964\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781661\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182595\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89847386\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974265\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979508\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375402\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.197974\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8984694\n",
            "Generator Loss:  13.858351\n",
            "Discriminator Loss:  1.5573204\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781605\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781645\n",
            "Generator Loss:  14.099364\n",
            "Discriminator Loss:  1.3177435\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177385\n",
            "Generator Loss:  13.798096\n",
            "Discriminator Loss:  1.6172158\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.138069\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578478\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177452\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578597\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583707\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380546\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979544\n",
            "Generator Loss:  14.099364\n",
            "Discriminator Loss:  1.3177419\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979502\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380589\n",
            "Generator Loss:  13.978858\n",
            "Discriminator Loss:  1.4375315\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8385787\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89847994\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182662\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578449\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974294\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177375\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95837426\n",
            "Generator Loss:  13.737843\n",
            "Discriminator Loss:  1.6771188\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177531\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380539\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95837677\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89847624\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177438\n",
            "Generator Loss:  13.798096\n",
            "Discriminator Loss:  1.6172252\n",
            "Generator Loss:  14.099364\n",
            "Discriminator Loss:  1.3177433\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578471\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.838585\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974372\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979532\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182619\n",
            "Generator Loss:  14.400634\n",
            "Discriminator Loss:  1.0182651\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375305\n",
            "Generator Loss:  13.858351\n",
            "Discriminator Loss:  1.5573338\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979482\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95836717\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375286\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8984729\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380591\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375284\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974296\n",
            "Generator Loss:  13.858351\n",
            "Discriminator Loss:  1.5573232\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95836544\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380529\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375365\n",
            "Generator Loss:  14.099364\n",
            "Discriminator Loss:  1.3177431\n",
            "Generator Loss:  14.460886\n",
            "Discriminator Loss:  0.95836645\n",
            "Generator Loss:  14.641648\n",
            "Discriminator Loss:  0.77869606\n",
            "Generator Loss:  14.641648\n",
            "Discriminator Loss:  0.77868557\n",
            "Generator Loss:  14.701902\n",
            "Discriminator Loss:  0.71878517\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781599\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177446\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.257842\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.838588\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380517\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380516\n",
            "Generator Loss:  13.737843\n",
            "Discriminator Loss:  1.6771127\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781577\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974287\n",
            "Generator Loss:  14.641648\n",
            "Discriminator Loss:  0.7786802\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979488\n",
            "Generator Loss:  14.340379\n",
            "Discriminator Loss:  1.078155\n",
            "Generator Loss:  13.978858\n",
            "Discriminator Loss:  1.4375339\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.197946\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.377639\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776356\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89847386\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583716\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.257851\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979536\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979526\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182652\n",
            "Generator Loss:  13.798096\n",
            "Discriminator Loss:  1.6172174\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781586\n",
            "Generator Loss:  13.798097\n",
            "Discriminator Loss:  1.6172166\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776385\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578459\n",
            "Generator Loss:  14.942917\n",
            "Discriminator Loss:  0.47920394\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380765\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583734\n",
            "Generator Loss:  14.340379\n",
            "Discriminator Loss:  1.0781606\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380541\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177575\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.018266\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979482\n",
            "Generator Loss:  13.798097\n",
            "Discriminator Loss:  1.6172162\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95836455\n",
            "Generator Loss:  13.858351\n",
            "Discriminator Loss:  1.5573263\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979535\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979586\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781627\n",
            "Generator Loss:  14.460886\n",
            "Discriminator Loss:  0.9583709\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89847255\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578479\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979504\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583694\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375314\n",
            "Generator Loss:  14.641648\n",
            "Discriminator Loss:  0.77869666\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781571\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380535\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.197953\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781579\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182617\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177357\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781589\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979482\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979452\n",
            "Generator Loss:  13.737843\n",
            "Discriminator Loss:  1.677113\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781575\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979524\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979558\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781617\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380489\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776374\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776352\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578423\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781605\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380591\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974225\n",
            "Generator Loss:  13.85835\n",
            "Discriminator Loss:  1.5573213\n",
            "Generator Loss:  14.099364\n",
            "Discriminator Loss:  1.3177365\n",
            "Generator Loss:  14.641648\n",
            "Discriminator Loss:  0.77868426\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578433\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380574\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380575\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974233\n",
            "Generator Loss:  14.400634\n",
            "Discriminator Loss:  1.0182648\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182651\n",
            "Generator Loss:  14.099364\n",
            "Discriminator Loss:  1.3177426\n",
            "Generator Loss:  14.701902\n",
            "Discriminator Loss:  0.71878225\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177474\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.9385365\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776299\n",
            "Generator Loss:  13.798097\n",
            "Discriminator Loss:  1.6172199\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177345\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979475\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177454\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776438\n",
            "Generator Loss:  14.340379\n",
            "Discriminator Loss:  1.0781533\n",
            "Generator Loss:  14.03911\n",
            "Discriminator Loss:  1.3776352\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.437532\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.958367\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.138054\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979451\n",
            "Generator Loss:  13.798097\n",
            "Discriminator Loss:  1.6172167\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583638\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380527\n",
            "Generator Loss:  14.460888\n",
            "Discriminator Loss:  0.95837057\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182692\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.138052\n",
            "Generator Loss:  13.798096\n",
            "Discriminator Loss:  1.6172123\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583726\n",
            "Generator Loss:  13.858351\n",
            "Discriminator Loss:  1.5573168\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89848614\n",
            "Generator Loss:  14.701902\n",
            "Discriminator Loss:  0.7187928\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979463\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.018259\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177463\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578454\n",
            "Generator Loss:  13.85835\n",
            "Discriminator Loss:  1.5573208\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95837176\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781553\n",
            "Generator Loss:  13.737843\n",
            "Discriminator Loss:  1.6771128\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8385723\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781572\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182647\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380529\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182614\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776321\n",
            "Generator Loss:  13.677589\n",
            "Discriminator Loss:  1.7370024\n",
            "Generator Loss:  13.737843\n",
            "Discriminator Loss:  1.6771107\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375324\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182651\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.377635\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979456\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.138051\n",
            "Generator Loss:  14.701902\n",
            "Discriminator Loss:  0.7187904\n",
            "Generator Loss:  13.677589\n",
            "Discriminator Loss:  1.7370077\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974222\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182594\n",
            "Generator Loss:  14.460888\n",
            "Discriminator Loss:  0.95837015\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578439\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974236\n",
            "Generator Loss:  13.737843\n",
            "Discriminator Loss:  1.6771251\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182607\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177372\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578478\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380515\n",
            "Generator Loss:  14.701902\n",
            "Discriminator Loss:  0.7187841\n",
            "Generator Loss:  13.617335\n",
            "Discriminator Loss:  1.7969074\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583663\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95836407\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182581\n",
            "Generator Loss:  14.701901\n",
            "Discriminator Loss:  0.7187841\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375291\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.83857536\n",
            "Generator Loss:  14.641647\n",
            "Discriminator Loss:  0.77868307\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.078153\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781565\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182652\n",
            "Generator Loss:  14.701902\n",
            "Discriminator Loss:  0.7187837\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583707\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974263\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380484\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182666\n",
            "Generator Loss:  13.798096\n",
            "Discriminator Loss:  1.6172154\n",
            "Generator Loss:  14.641647\n",
            "Discriminator Loss:  0.77867794\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380558\n",
            "Generator Loss:  13.978858\n",
            "Discriminator Loss:  1.4375415\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95837706\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95836127\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375293\n",
            "Generator Loss:  14.03911\n",
            "Discriminator Loss:  1.3776364\n",
            "Generator Loss:  14.340379\n",
            "Discriminator Loss:  1.078156\n",
            "Generator Loss:  14.400634\n",
            "Discriminator Loss:  1.018258\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781548\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781795\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89846647\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380541\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8984739\n",
            "Generator Loss:  13.798096\n",
            "Discriminator Loss:  1.6172177\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8385717\n",
            "Generator Loss:  14.099364\n",
            "Discriminator Loss:  1.3177375\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380478\n",
            "Generator Loss:  13.798096\n",
            "Discriminator Loss:  1.6172192\n",
            "Generator Loss:  13.978858\n",
            "Discriminator Loss:  1.4375283\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.138051\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974284\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.437531\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781541\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182589\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578399\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380525\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177578\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8984753\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8385743\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380548\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375299\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979553\n",
            "Generator Loss:  13.737843\n",
            "Discriminator Loss:  1.6771196\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583662\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974215\n",
            "Generator Loss:  14.099364\n",
            "Discriminator Loss:  1.3177391\n",
            "Generator Loss:  13.617335\n",
            "Discriminator Loss:  1.7968981\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578392\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781517\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979463\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380458\n",
            "Generator Loss:  14.03911\n",
            "Discriminator Loss:  1.3776355\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578437\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.197942\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781584\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583648\n",
            "Generator Loss:  13.737843\n",
            "Discriminator Loss:  1.6771098\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979423\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578411\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583685\n",
            "Generator Loss:  13.617335\n",
            "Discriminator Loss:  1.796898\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776411\n",
            "Generator Loss:  13.677589\n",
            "Discriminator Loss:  1.7370114\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578421\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8385849\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380484\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8385704\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89847296\n",
            "Generator Loss:  13.737843\n",
            "Discriminator Loss:  1.6771086\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380548\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974234\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974239\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8385781\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776321\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974229\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.197944\n",
            "Generator Loss:  14.52114\n",
            "Discriminator Loss:  0.89847165\n",
            "Generator Loss:  14.882664\n",
            "Discriminator Loss:  0.53909636\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.317735\n",
            "Generator Loss:  13.978858\n",
            "Discriminator Loss:  1.437525\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182567\n",
            "Generator Loss:  13.737843\n",
            "Discriminator Loss:  1.6771109\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182577\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979438\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578378\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8984694\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8984648\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979455\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.83857226\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.197946\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583685\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8385793\n",
            "Generator Loss:  14.762156\n",
            "Discriminator Loss:  0.6588857\n",
            "Generator Loss:  13.677589\n",
            "Discriminator Loss:  1.7370077\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578467\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177342\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781533\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.377636\n",
            "Generator Loss:  13.798097\n",
            "Discriminator Loss:  1.6172124\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177341\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380515\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182583\n",
            "Generator Loss:  13.737843\n",
            "Discriminator Loss:  1.6771072\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776298\n",
            "Generator Loss:  13.677589\n",
            "Discriminator Loss:  1.73701\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95836234\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182564\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583671\n",
            "Generator Loss:  14.641647\n",
            "Discriminator Loss:  0.7786765\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182564\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578373\n",
            "Generator Loss:  14.039112\n",
            "Discriminator Loss:  1.3776314\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583592\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583663\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781531\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182608\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380563\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380464\n",
            "Generator Loss:  14.762156\n",
            "Discriminator Loss:  0.65888596\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578375\n",
            "Generator Loss:  14.460888\n",
            "Discriminator Loss:  0.9583615\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776308\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8385755\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781585\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8385724\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8385745\n",
            "Generator Loss:  14.460888\n",
            "Discriminator Loss:  0.9583612\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182544\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8984717\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95836115\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380451\n",
            "Generator Loss:  14.82241\n",
            "Discriminator Loss:  0.599\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177335\n",
            "Generator Loss:  13.677589\n",
            "Discriminator Loss:  1.7370031\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177321\n",
            "Generator Loss:  14.039112\n",
            "Discriminator Loss:  1.3776304\n",
            "Generator Loss:  14.03911\n",
            "Discriminator Loss:  1.3776314\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380553\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.138048\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380508\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.317735\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380532\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380467\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583615\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578368\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380465\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.83857435\n",
            "Generator Loss:  14.099364\n",
            "Discriminator Loss:  1.317735\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.257836\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974222\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8984688\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974225\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.83856976\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979439\n",
            "Generator Loss:  13.737843\n",
            "Discriminator Loss:  1.6771071\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781499\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380501\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583608\n",
            "Generator Loss:  14.762156\n",
            "Discriminator Loss:  0.6588814\n",
            "Generator Loss:  14.641649\n",
            "Discriminator Loss:  0.7786757\n",
            "Generator Loss:  14.641648\n",
            "Discriminator Loss:  0.77867556\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578387\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583628\n",
            "Generator Loss:  14.641648\n",
            "Discriminator Loss:  0.7786759\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380537\n",
            "Generator Loss:  14.581395\n",
            "Discriminator Loss:  0.83857906\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781538\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781518\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776296\n",
            "Generator Loss:  14.03911\n",
            "Discriminator Loss:  1.4775957\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380455\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380465\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375235\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177342\n",
            "Generator Loss:  13.85835\n",
            "Discriminator Loss:  1.5573151\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182576\n",
            "Generator Loss:  14.701902\n",
            "Discriminator Loss:  0.71877694\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.83857065\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177409\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974169\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979437\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182543\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974198\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89846295\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.018254\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380454\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974213\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380477\n",
            "Generator Loss:  14.460888\n",
            "Discriminator Loss:  0.95836073\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781552\n",
            "Generator Loss:  14.701902\n",
            "Discriminator Loss:  0.71877927\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177301\n",
            "Generator Loss:  14.641649\n",
            "Discriminator Loss:  0.7786753\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578386\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974341\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583652\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380464\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8984643\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979549\n",
            "Generator Loss:  13.798097\n",
            "Discriminator Loss:  1.6172162\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.078152\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182849\n",
            "Generator Loss:  13.677589\n",
            "Discriminator Loss:  1.7370002\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583625\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578404\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781517\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.257835\n",
            "Generator Loss:  14.099364\n",
            "Discriminator Loss:  1.3177369\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781484\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375265\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578349\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.197943\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375238\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95836306\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781581\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380476\n",
            "Generator Loss:  14.03911\n",
            "Discriminator Loss:  1.3776299\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8385724\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.437523\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380451\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578413\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979423\n",
            "Generator Loss:  14.762156\n",
            "Discriminator Loss:  0.65887976\n",
            "Generator Loss:  14.641648\n",
            "Discriminator Loss:  0.7786736\n",
            "Generator Loss:  14.400634\n",
            "Discriminator Loss:  1.0182539\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979553\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.018261\n",
            "Generator Loss:  14.099364\n",
            "Discriminator Loss:  1.3177352\n",
            "Generator Loss:  14.762156\n",
            "Discriminator Loss:  0.6588921\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.018258\n",
            "Generator Loss:  14.099364\n",
            "Discriminator Loss:  1.317731\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578355\n",
            "Generator Loss:  14.701902\n",
            "Discriminator Loss:  0.7187758\n",
            "Generator Loss:  14.400634\n",
            "Discriminator Loss:  1.0182612\n",
            "Generator Loss:  14.039112\n",
            "Discriminator Loss:  1.3776243\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89846367\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979455\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974188\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781505\n",
            "Generator Loss:  13.85835\n",
            "Discriminator Loss:  1.557318\n",
            "Generator Loss:  14.400634\n",
            "Discriminator Loss:  1.0182571\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578464\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.317735\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8984669\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781503\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89846414\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8385669\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375318\n",
            "Generator Loss:  14.82241\n",
            "Discriminator Loss:  0.59898615\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781527\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578353\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578362\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177321\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89846337\n",
            "Generator Loss:  14.641647\n",
            "Discriminator Loss:  0.7786726\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776267\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.437525\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578384\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979445\n",
            "Generator Loss:  14.701902\n",
            "Discriminator Loss:  0.7187787\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8984649\n",
            "Generator Loss:  13.85835\n",
            "Discriminator Loss:  1.5573108\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583724\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182611\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89846206\n",
            "Generator Loss:  14.762156\n",
            "Discriminator Loss:  0.65888023\n",
            "Generator Loss:  14.400634\n",
            "Discriminator Loss:  1.0182563\n",
            "Generator Loss:  14.52114\n",
            "Discriminator Loss:  0.89846253\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95835906\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979533\n",
            "Generator Loss:  14.641648\n",
            "Discriminator Loss:  0.7786711\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583593\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8984642\n",
            "Generator Loss:  13.798096\n",
            "Discriminator Loss:  1.6172082\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979401\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380476\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177326\n",
            "Generator Loss:  13.858351\n",
            "Discriminator Loss:  1.5573156\n",
            "Generator Loss:  14.762156\n",
            "Discriminator Loss:  0.65888536\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781472\n",
            "Generator Loss:  14.099364\n",
            "Discriminator Loss:  1.3177321\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177365\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177316\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583578\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974239\n",
            "Generator Loss:  13.617334\n",
            "Discriminator Loss:  1.7968967\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578368\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95836705\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.138045\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8984603\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781536\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8385714\n",
            "Generator Loss:  13.798096\n",
            "Discriminator Loss:  1.6172144\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95835996\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182528\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578368\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583578\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89846456\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.497421\n",
            "Generator Loss:  14.701901\n",
            "Discriminator Loss:  0.71877587\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974144\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583558\n",
            "Generator Loss:  14.641649\n",
            "Discriminator Loss:  0.7786701\n",
            "Generator Loss:  14.460888\n",
            "Discriminator Loss:  0.9583596\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380543\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.018256\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781486\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380489\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380476\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380515\n",
            "Generator Loss:  14.641648\n",
            "Discriminator Loss:  0.778673\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583621\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781481\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177365\n",
            "Generator Loss:  13.85835\n",
            "Discriminator Loss:  1.5573113\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380455\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979375\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776276\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8984697\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.197938\n",
            "Generator Loss:  14.762156\n",
            "Discriminator Loss:  0.6588774\n",
            "Generator Loss:  13.798096\n",
            "Discriminator Loss:  1.6172076\n",
            "Generator Loss:  13.737843\n",
            "Discriminator Loss:  1.6771057\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578373\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583626\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.377626\n",
            "Generator Loss:  14.701902\n",
            "Discriminator Loss:  0.7187787\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979461\n",
            "Generator Loss:  14.701902\n",
            "Discriminator Loss:  0.7187749\n",
            "Generator Loss:  14.701902\n",
            "Discriminator Loss:  0.7187797\n",
            "Generator Loss:  14.641648\n",
            "Discriminator Loss:  0.7786739\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781488\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979394\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578378\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375336\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578332\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979375\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583552\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979402\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578337\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177359\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979382\n",
            "Generator Loss:  14.641648\n",
            "Discriminator Loss:  0.77866894\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.018251\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578413\n",
            "Generator Loss:  13.858351\n",
            "Discriminator Loss:  1.5573204\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979386\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380428\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979388\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979411\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781517\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974148\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95836544\n",
            "Generator Loss:  13.617335\n",
            "Discriminator Loss:  1.7968935\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979383\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182548\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781453\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578343\n",
            "Generator Loss:  13.376321\n",
            "Discriminator Loss:  2.036473\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89846575\n",
            "Generator Loss:  14.641647\n",
            "Discriminator Loss:  0.7786695\n",
            "Generator Loss:  14.762156\n",
            "Discriminator Loss:  0.6588787\n",
            "Generator Loss:  13.677589\n",
            "Discriminator Loss:  1.7370038\n",
            "Generator Loss:  14.641648\n",
            "Discriminator Loss:  0.77867174\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781446\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375196\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781547\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.497431\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380471\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380417\n",
            "Generator Loss:  13.798096\n",
            "Discriminator Loss:  1.6172056\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8984664\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979396\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.838565\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.497422\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8385688\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.257834\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182548\n",
            "Generator Loss:  14.701902\n",
            "Discriminator Loss:  0.71877897\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979454\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781525\n",
            "Generator Loss:  13.798097\n",
            "Discriminator Loss:  1.6172059\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177269\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375199\n",
            "Generator Loss:  13.737843\n",
            "Discriminator Loss:  1.677101\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776245\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.197938\n",
            "Generator Loss:  14.03911\n",
            "Discriminator Loss:  1.3776258\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.317734\n",
            "Generator Loss:  14.641648\n",
            "Discriminator Loss:  0.7786721\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578351\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781491\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.958359\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578318\n",
            "Generator Loss:  13.918603\n",
            "Discriminator Loss:  1.4974178\n",
            "Generator Loss:  14.701902\n",
            "Discriminator Loss:  0.71877533\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8385632\n",
            "Generator Loss:  14.460888\n",
            "Discriminator Loss:  0.95836264\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578417\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583598\n",
            "Generator Loss:  13.858351\n",
            "Discriminator Loss:  1.557311\n",
            "Generator Loss:  13.85835\n",
            "Discriminator Loss:  1.5573142\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583661\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583576\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.2979093\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380402\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375286\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979469\n",
            "Generator Loss:  14.701902\n",
            "Discriminator Loss:  0.7187729\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974145\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979408\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375242\n",
            "Generator Loss:  14.400634\n",
            "Discriminator Loss:  1.0182543\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95835507\n",
            "Generator Loss:  14.400634\n",
            "Discriminator Loss:  1.0182499\n",
            "Generator Loss:  14.400634\n",
            "Discriminator Loss:  1.018254\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182543\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.377624\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380446\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979392\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375181\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8385674\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375153\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8984666\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8385676\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979365\n",
            "Generator Loss:  14.641648\n",
            "Discriminator Loss:  0.7786722\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.8984628\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.437517\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781472\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375248\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.838567\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182512\n",
            "Generator Loss:  13.85835\n",
            "Discriminator Loss:  1.5573123\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177285\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.89845973\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375193\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979382\n",
            "Generator Loss:  14.460886\n",
            "Discriminator Loss:  0.95836604\n",
            "Generator Loss:  13.617335\n",
            "Discriminator Loss:  1.7968951\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95835364\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578313\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95835775\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95835763\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182495\n",
            "Generator Loss:  14.701902\n",
            "Discriminator Loss:  0.7187737\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380444\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979386\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177276\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380423\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.898463\n",
            "Generator Loss:  14.400634\n",
            "Discriminator Loss:  1.0182574\n",
            "Generator Loss:  14.460888\n",
            "Discriminator Loss:  0.95835483\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182524\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781565\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177313\n",
            "Generator Loss:  14.099364\n",
            "Discriminator Loss:  1.3177378\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776267\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781503\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578367\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95836294\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776264\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380441\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974135\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177289\n",
            "Generator Loss:  14.400633\n",
            "Discriminator Loss:  1.0182502\n",
            "Generator Loss:  14.400634\n",
            "Discriminator Loss:  1.0182517\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776267\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578347\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.9583553\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974148\n",
            "Generator Loss:  14.460888\n",
            "Discriminator Loss:  0.95836675\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8385611\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781534\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177311\n",
            "Generator Loss:  13.737843\n",
            "Discriminator Loss:  1.6770979\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979389\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.078146\n",
            "Generator Loss:  14.460887\n",
            "Discriminator Loss:  0.95835495\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380395\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.83856714\n",
            "Generator Loss:  14.581394\n",
            "Discriminator Loss:  0.8385657\n",
            "Generator Loss:  14.641648\n",
            "Discriminator Loss:  0.7786689\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979388\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380397\n",
            "Generator Loss:  13.737843\n",
            "Discriminator Loss:  1.677101\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776398\n",
            "Generator Loss:  14.762156\n",
            "Discriminator Loss:  0.65887916\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578378\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375172\n",
            "Generator Loss:  14.099365\n",
            "Discriminator Loss:  1.3177296\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776233\n",
            "Generator Loss:  13.677589\n",
            "Discriminator Loss:  1.7370062\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.1380424\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979351\n",
            "Generator Loss:  13.978857\n",
            "Discriminator Loss:  1.4375206\n",
            "Generator Loss:  14.641648\n",
            "Discriminator Loss:  0.77866936\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776252\n",
            "Generator Loss:  14.641648\n",
            "Discriminator Loss:  0.77866936\n",
            "Generator Loss:  14.34038\n",
            "Discriminator Loss:  1.0781467\n",
            "Generator Loss:  14.400634\n",
            "Discriminator Loss:  1.0182514\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776221\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578351\n",
            "Generator Loss:  14.2198715\n",
            "Discriminator Loss:  1.1979363\n",
            "Generator Loss:  13.737843\n",
            "Discriminator Loss:  1.6771014\n",
            "Generator Loss:  14.521141\n",
            "Discriminator Loss:  0.898458\n",
            "Generator Loss:  14.280127\n",
            "Discriminator Loss:  1.1380382\n",
            "Generator Loss:  14.460888\n",
            "Discriminator Loss:  0.9583535\n",
            "Generator Loss:  14.641648\n",
            "Discriminator Loss:  0.77866936\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578323\n",
            "Generator Loss:  14.159618\n",
            "Discriminator Loss:  1.2578342\n",
            "Generator Loss:  14.701902\n",
            "Discriminator Loss:  0.71877515\n",
            "Generator Loss:  14.280126\n",
            "Discriminator Loss:  1.138041\n",
            "Generator Loss:  13.918604\n",
            "Discriminator Loss:  1.4974179\n",
            "Generator Loss:  14.099364\n",
            "Discriminator Loss:  1.317729\n",
            "Generator Loss:  14.039111\n",
            "Discriminator Loss:  1.3776217\n",
            "Generator Loss:  14.099364\n",
            "Discriminator Loss:  1.3177251\n",
            "Generator Loss:  14.822409\n",
            "Discriminator Loss:  0.598984\n",
            "Generator Loss:  13.737843\n",
            "Discriminator Loss:  1.6771061\n",
            "Generator Loss:  14.219872\n",
            "Discriminator Loss:  1.1979373\n",
            "Generator Loss:  14.161016\n",
            "Discriminator Loss:  1.20263\n",
            "Generator Loss:  14.762156\n",
            "Discriminator Loss:  0.658895\n",
            "Generator Loss:  15.304439\n",
            "Discriminator Loss:  0.119864516\n",
            "Generator Loss:  15.304439\n",
            "Discriminator Loss:  0.119910054\n",
            "Generator Loss:  15.364693\n",
            "Discriminator Loss:  0.060076803\n",
            "Generator Loss:  15.364693\n",
            "Discriminator Loss:  0.060160775\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.00037407223\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0005371702\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.00078509643\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0009734794\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0013882915\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.001698404\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.007818673\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.006609771\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0031089606\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.003861562\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.004355088\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0051238253\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.005899286\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.006028516\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.009293869\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.009399002\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.010856677\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.011291955\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.010331575\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.011482686\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.009554114\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.016903156\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.009549874\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0151304705\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.01035836\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.039257493\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0118277315\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.017783765\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.029680695\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.013239124\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.026498085\n",
            "Generator Loss:  15.304439\n",
            "Discriminator Loss:  0.13222489\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.009944632\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.009948312\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.012190675\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.008916341\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.011128742\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.009196399\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.008305509\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.011312211\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.019144643\n",
            "Generator Loss:  15.364693\n",
            "Discriminator Loss:  0.08674786\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.007906962\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.022807451\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0070508746\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.007516619\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.011747652\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0066941176\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.00762954\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.005970652\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.014052082\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0055101714\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.045091093\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.005648909\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.023829125\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.005607428\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.019018963\n",
            "Generator Loss:  15.364693\n",
            "Discriminator Loss:  0.06470374\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.005638309\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.011947599\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.009656195\n",
            "Generator Loss:  15.364693\n",
            "Discriminator Loss:  0.06934489\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.006141324\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0048225746\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0038050138\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.00729302\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0036001117\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0036031473\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.006217108\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.00368736\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0038410039\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0032412584\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0033534481\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.009563513\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.003207459\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0062083383\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0040578702\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0030749254\n",
            "Generator Loss:  15.364693\n",
            "Discriminator Loss:  0.06303529\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0029364699\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0031062285\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0031533323\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0026054226\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0027586329\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0028849605\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0027086118\n",
            "Generator Loss:  15.364693\n",
            "Discriminator Loss:  0.06268066\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0024890024\n",
            "Generator Loss:  15.364693\n",
            "Discriminator Loss:  0.070721924\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0026787326\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0032186261\n",
            "Generator Loss:  15.364693\n",
            "Discriminator Loss:  0.062536135\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0025439009\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0025199244\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0038110905\n",
            "Generator Loss:  15.364693\n",
            "Discriminator Loss:  0.06325436\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0023645237\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0035251854\n",
            "Generator Loss:  15.364693\n",
            "Discriminator Loss:  0.06229183\n",
            "Generator Loss:  15.364693\n",
            "Discriminator Loss:  0.062340144\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0022246444\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0022010894\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.004920481\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0020293696\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0021247393\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0040175808\n",
            "Generator Loss:  15.364693\n",
            "Discriminator Loss:  0.06205651\n",
            "Generator Loss:  15.364693\n",
            "Discriminator Loss:  0.06251382\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.002047006\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.003509218\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0021570916\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0019262519\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0018453598\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.10000002\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0019091365\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0020636274\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0016704502\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0017989732\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0020444663\n",
            "Generator Loss:  15.364693\n",
            "Discriminator Loss:  0.061810616\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.001849253\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0016945852\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0016854804\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0016514395\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.001851379\n",
            "Generator Loss:  15.364693\n",
            "Discriminator Loss:  0.0626315\n",
            "Generator Loss:  15.364693\n",
            "Discriminator Loss:  0.061598536\n",
            "Generator Loss:  15.364693\n",
            "Discriminator Loss:  0.062047306\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0016241942\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0016015392\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0016678992\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0019503285\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0016417557\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0015846925\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0014042048\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.002153318\n",
            "Generator Loss:  15.364693\n",
            "Discriminator Loss:  0.06143863\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0016859686\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0016360183\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0018477675\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.004613986\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0015148397\n",
            "Generator Loss:  15.424946\n",
            "Discriminator Loss:  0.0015004883\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-83ec25c6b017>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-dec5f891a977>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data, epochs)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m       \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-ee657222538d>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(images)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Calculate gradients of loss functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mgenerator_gradients\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mgenerator_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgenerator_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mdiscriminator_gradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Optimise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1088\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    157\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MeanGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0moutput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0mfactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_size\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m     \u001b[0mfactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msum_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    270\u001b[0m   \"\"\"\n\u001b[1;32m    271\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 272\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    281\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Uf4TIsoSWWaY",
        "outputId": "d5b3ae0e-0a1e-4026-a7d1-58758b486cca"
      },
      "source": [
        "test_image_noise = np.random.randn(1,100)\n",
        "generated_test_image = generator_model(test_image_noise)\n",
        "plt.imshow(tf.reshape(generated_test_image,(28,28)),cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f2601387d10>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXYUlEQVR4nO3dfXDU1bkH8O+jQKqAlBAIEEBB0ErpXHonQ28LY8W3gnSK+oct6i1KEVukgx1n6ttY0U5n6OVqcUZrS69MowPSThGKlaoIKFCrJiAiL/KiAwSIgMQCifL+3D+ydFKb8z10N9nde8/3M8Mk7Dcnvx+bfdjNnt85j7k7ROT/v7MKfQIikh8qdpFEqNhFEqFiF0mEil0kEe3yebCOHTt6aWlp1uPNLJjFZhViOfveuR771KlTND/rLP5/buzc2PELeexYnst93tbH/r+qvr4ejY2NLf7jcip2MxsF4DEAZwP4H3efzr6+tLQUU6dOZd+PHq9du/Dpnjhxgo49duwYzTt06EDzkpKSYHb06FE69tNPP6X5Oeeck/WxY8cv5LEBfr+3b9+ejo39TI4fP05z9pg4++yz6djYf4K5PrnkgtXJzJkzg1nWL+PN7GwATwAYDWAwgHFmNjjb7ycibSuX39mHAdjm7h+4+zEA8wCMbZ3TEpHWlkuxVwCobfb3XZnb/oGZTTKzGjOraWhoyOFwIpKLNn833t1nuXulu1d26tSprQ8nIgG5FPtuAH2b/b1P5jYRKUK5FHs1gEFm1t/MOgD4DoBFrXNaItLasp56c/cTZjYFwEtomnqb7e4bImNw8uTJYB6bxunZs2cwi03TvP/++zSvq6uj+bBhw4JZbHpq9erVNK+traX517/+dZqzf3vs2Lt38xdjX/va12gemz5bv359MGtsbKRjhwwZQvPY9Bm7X2NTtWVlZTSPTRMfOXIk6/GxayPYtB7Lcppnd/fFABbn8j1EJD90uaxIIlTsIolQsYskQsUukggVu0giVOwiicjrevaYjh070pzNTdbX19OxbH4fAPr3709zNqcbmyePzel+4QtfoHlsueXOnTuDWWwZ6KBBg2gem0+OzdOzf3ufPn1yOvaBAwdozuarO3fuTMfGxK4JyWUJbGwseyyy+0zP7CKJULGLJELFLpIIFbtIIlTsIolQsYskIu9Tb2w65OOPP6Zje/ToEcy6du1Kx8amx6qrq2l+4403BjO29BYAtm7dSvNly5bRfPLkyTRnx48de8WKFTSfMGECzdnPBABeeOGFYLZ27Vo6dsyYMTTv0qULzdny3sOHD9OxAwcOpHlsSfXBgwdpzqZTc9manI3VM7tIIlTsIolQsYskQsUukggVu0giVOwiiVCxiySiqJa4xubK2fxibB49tlyysrKS5myJbGy+OHbskSNH0jy2RHbNmjVZH/vSSy/N6dhsq+jY8YcOHZrTsXft2kVzpry8PKdjx7rjtmWXV3afaomriKjYRVKhYhdJhIpdJBEqdpFEqNhFEqFiF0lEXufZYy2bY22T2XbPvXv3pmM3btxI8+eff57m06dPD2axraAffPBBms+ePZvmVVVVNL/kkkuC2QMPPEDHPv300zT/5S9/SfOLLrqI5o888kgwW7duHR17991307xfv340X7hwYTDbsmULHTt8+HCax9bS79mzh+bsmpHYtREFadlsZtsBHAZwEsAJd+dXpohIwbTGM/tId/+oFb6PiLQh/c4ukohci90BvGxmq81sUktfYGaTzKzGzGoaGxtzPJyIZCvXl/Ej3H23mfUAsMTM3nP3f9jB0N1nAZgFABUVFdlf/S8iOcnpmd3dd2c+7gOwAMCw1jgpEWl9WRe7mXU0s86nPwdwNQC+3lFECiaXl/HlABZk5gTbAZjr7i/mcjKxuXLWJnf79u10bPv27Wk+duxYmrN9xv/yl7/QsSUlJTSfOHEizQ8dOkTz1157LZjF9je/5ZZbaB7bX/2NN96gebt24YfYN7/5TTo29h5PbC09c/HFF9P82LFjNI/9TNg8OsDbLsdku54962J39w8A/Fu240UkvzT1JpIIFbtIIlTsIolQsYskQsUukoi8byXNluDFtgYeMGBAMIttSxybppk/fz7NR4wYEcxi03arVq2i+RNPPEHzP/zhDzS//vrrsz72r371K5o/88wzNI+1Va6pqQlmsfv84YcfpvlXv/pVms+dOzeYvfvuu3TsFVdcQfNzzz2X5rGpYFYHsWnibOmZXSQRKnaRRKjYRRKhYhdJhIpdJBEqdpFEqNhFEpH3eXa2BK+iooKOZcsO33nnHTo2NnfJ5qoBvtxy5cqVdOznPvc5mt9xxx00jy0zXbZsWdbHvv3222ne0NBA89i/nS2xjd3nn3zyCc3ffvttmrNlpEOGDKFjjx8/TvP6+nqax7Clv7F2zrGtpkP0zC6SCBW7SCJU7CKJULGLJELFLpIIFbtIIlTsIomw2Jxea+rdu7ezed2PPuL9Ia+55ppgVlpaSsc+9thjNI/N07P2v927d6djx40bR/PYVtSxtfhlZWXBLDaX/de//pXmq1evpnm3bt1ofuuttwazDRs20LFsPToAnHfeeTRn7aL37dtHx9500000j123EfuZsa2mO3bsSMeedVb4OfrRRx9FbW1tixPxemYXSYSKXSQRKnaRRKjYRRKhYhdJhIpdJBEqdpFE5HU9u5nRNcb9+/en49na6vfee4+Ojc1d3nbbbTT/8MMPg9mf/vQnOjY2H/zTn/6U5nV1dTRn+6937tyZjn3ooYdozv7dALBo0SKas/3VJ0+eTMceOHCA5itWrKA5WzPO+gAA8XbRsWtCYtevsH0GYmNPnjxJ85DoM7uZzTazfWa2vtltpWa2xMy2Zj52zeroIpI3Z/Iy/rcARn3mtnsALHX3QQCWZv4uIkUsWuzuvgLAZ/fgGQugKvN5FYBrW/m8RKSVZfsGXbm7n/5F8kMA5aEvNLNJZlZjZjWx34NEpO3k/G68N72bEHxHwd1nuXulu1fG3iQTkbaTbbHvNbNeAJD5yJcQiUjBZVvsiwCMz3w+HsAfW+d0RKStRNezm9mzAC4DUAZgL4AHASwE8HsA/QDsAHCDu0c30q6oqKDr2WN7cV955ZXB7POf/zwdG+tDvmnTJppXVVUFM7aeHAAmTJhA89ia8dh6d7am/MYbb8zp2LG57Nj9zn7emzdvpmPZfQ7Er5149NFHg1nssRa739gcPgCsW7eO5qzuunTpQseyfePZevboRTXuHtp5gXerF5GiostlRRKhYhdJhIpdJBEqdpFEqNhFEpH3ls1sG9y+ffvSsUePHg1m1dXVdGysdfHNN99M80OHDgWzV155hY6NTRHde++9NP/b3/5G8+effz6YnXPOOW167MWLF9Oc3e+TJk2iY9l9DuTWLnr48OF07JEjR2i+d+9emsfaKrOlv7kscWVj9cwukggVu0giVOwiiVCxiyRCxS6SCBW7SCJU7CKJKKqWzbG5y+uuuy6YxVoHT58+neZr1qyh+dKlS4NZeXlwVy4AvNU0ALz22ms0j20l3aNHj2B22WWX5XTs3bt3Z31sABgzZkwwa+vltffcE94HddeuXXTsj370I5qXlJTQfNWqVTQ/fvx4MOvZsycdy65VmTFjBnbu3KmWzSIpU7GLJELFLpIIFbtIIlTsIolQsYskQsUukoiiatk8cOBAOv7gwYPBbP369cEMADp16kTzKVOm0JzNNz/33HN0bGlpKc3ZlscAUFtbS/M5c+YEs9hc9MyZM2kem4/+3e9+R3PWrvr++++nY2Ptol988UWas7X0bP4f4I81IH5usfXs7DERa8nM5ui1nl1EVOwiqVCxiyRCxS6SCBW7SCJU7CKJULGLJCKv69ljLZsPHDhAx3/jG98IZrH55Mcff5zmGzdupPmzzz4bzGItm7/73e/S/K233qJ5bN03W8t//fXX53Ts2Dr/2DUEN910UzDbsGEDHbtw4UKad+7cmeYPP/xwMIvNk0+ePJnmsZbNr7/+Os1PnToVzHr37k3Hsjn8nNazm9lsM9tnZuub3TbNzHab2drMH747g4gU3Jm8jP8tgFEt3P4Ldx+a+cPbgohIwUWL3d1XAKjPw7mISBvK5Q26KWa2LvMyv2voi8xskpnVmFlNY2NjDocTkVxkW+xPArgQwFAAdQAeCX2hu89y90p3r4w1OBSRtpNVsbv7Xnc/6e6nAPwGwLDWPS0RaW1ZFbuZ9Wr21+sA8PWlIlJw0fXsZvYsgMsAlJnZLgAPArjMzIYCcADbAYQnzz+D7Xndr18/OvbTTz8NZps3b6ZjY/3Zx48fT/OPP/44mMXWVcd+fXnggQdoHrv+YMGCBcEsto5/2rRpNK+v5+/NLlq0iOasD/nUqVPp2Fhv+GXLltGc7e1+9dVX07HssQbE1/mzfRsAoGvX4Ntc0fXs2fZnjxa7u49r4eanYuNEpLjoclmRRKjYRRKhYhdJhIpdJBEqdpFEFFXL5v3799Px3/rWt4JZbKnljBkzaL527Vqas+m17t2707Gs1TQQb5sc20qatU2+/PLL6dhXX32V5nv27Mn62AAwevToYFZdXU3HvvHGGzRn01cAcOeddwaznTt30rGxba5jU7lLliyh+ZEjR4LZgAED6Fg2rTd9+nTs2LFDLZtFUqZiF0mEil0kESp2kUSo2EUSoWIXSYSKXSQRRdWyOTa/yJY8xrYlZq2DAeAHP/gBzdlcd2zL41yvAdi+fTvN586dG8xic9Gxls07duyg+bx582jOtvj+yU9+QseyNtkA8MILL9CcLS2OXfsQa9kc23o8tsS1V69ewSy2xJXN0bMtqvXMLpIIFbtIIlTsIolQsYskQsUukggVu0giVOwiich7y+bvf//7wZxt1wwAI0eODGZdunShY596im+IG9uK+te//nUwYy2TgXj731hb5NiWyWweP9YuuqamhuYrV67M+tgAcOuttwaz2LUR8+fPp3lbtmz+4Q9/SPMOHTrQPLZHwdGjR4NZ7HoTth37z3/+c61nF0mdil0kESp2kUSo2EUSoWIXSYSKXSQRKnaRROR1PTvQtKY9pKKigo5lbXS3bdtGx8b2+f72t79Nc7aWPjYPHmubfNddd9E81jaZreuOHfvee+/N6diLFy+mOVtTHpvLjl13sXz5cpqzn/moUaPo2E8++YTmW7ZsoTl7nAN8PXvs2hd2bjmtZzezvma23Mw2mtkGM5uaub3UzJaY2dbMR75LgogU1Jm8jD8B4C53HwzgPwDcYWaDAdwDYKm7DwKwNPN3ESlS0WJ39zp3X5P5/DCATQAqAIwFUJX5sioA17bVSYpI7v6lN+jM7AIAXwbwJoByd6/LRB8CKA+MmWRmNWZW09jYmMOpikguzrjYzawTgPkA7nT3Q80zb3pHocV3Fdx9lrtXunsle7NGRNrWGRW7mbVHU6HPcffnMjfvNbNembwXgH1tc4oi0hqiS1ytaQ6hCkC9u9/Z7PYZAA64+3QzuwdAqbv/mH2viooK2rI5Ns1z5ZVXBjO2ZTEAzJo1i+ax5ZZVVVXBLNayeeLEiTR/8803c8rLysqC2Q033EDHvv766zSPtbJmxwb4lObbb79Nx8baHsd+5mxaMbY9d6xlc0lJCc1feuklmjc0NASzL33pS3Qsm9b72c9+Flzieibz7MMB/CeAd83s9E/+PgDTAfzezL4HYAcA/qgSkYKKFru7rwIQ+q/kitY9HRFpK7pcViQRKnaRRKjYRRKhYhdJhIpdJBF5X+Larl34kH379qVjDx06FMy2bt1Kx8aWet588800r6urC2Yvv/wyHRvbbvm+++6j+c6dO2m+YMGCYBZr2fzQQw+12bEBPhf+4x/TyzKwZ88emsfu91xaNrMlzUC8nTTb7hkALrjggmB2/PhxOlYtm0WEUrGLJELFLpIIFbtIIlTsIolQsYskQsUukoi8z7OzecC9e/fSsWxucvDgwXTspk2baP7nP/+Z5l/5yleCWWxb4rfeeovmsXbSbC09AFx7bXj7v9h69SeffJLm8+bNy/rYsePPnj2bjo3tQXDVVVfRfP369cEstlaetRYH4o+3WMvm2traYHbJJZfQsaxVNZvf1zO7SCJU7CKJULGLJELFLpIIFbtIIlTsIolQsYskIu/z7GwesLy8xQ5Sf8daNsfWXcdaNsfmyg8ePBjMYvu6n3vuuTSfMGECzWOti9mcbqwLT2w+OXbsV199lebs+LF/d2xNeewaAvYzZz0IgHjL5tj+CbH17GzvhhMnTtCxWs8uIpSKXSQRKnaRRKjYRRKhYhdJhIpdJBEqdpFEROfZzawvgKcBlANwALPc/TEzmwbgNgD7M196n7svjn0/Ng+4f//+YAbwucmLL76Yjo3Niy5btozmlZWVwezyyy+nY2N9yOfOnUvz4cOH03z06NHBrLq6mo6NrSmP5WPGjKE5O/6cOXPo2JkzZ9I8Nle+ZcuWYLZ8+XI6duLEiTT/4he/SPOVK1fSnF0XEvveHTp0CGZsfv9MLqo5AeAud19jZp0BrDaz0yv/f+Hu/30G30NECuxM+rPXAajLfH7YzDYBqGjrExOR1vUv/c5uZhcA+DKA09eHTjGzdWY228xa7DNkZpPMrMbMahobG3M6WRHJ3hkXu5l1AjAfwJ3ufgjAkwAuBDAUTc/8j7Q0zt1nuXulu1fGrtMWkbZzRsVuZu3RVOhz3P05AHD3ve5+0t1PAfgNgGFtd5oikqtosZuZAXgKwCZ3f7TZ7b2afdl1AMJbeYpIwZm78y8wGwFgJYB3AZyeN7sPwDg0vYR3ANsB3J55My+oT58+PmXKlGDevn17ei6s/S9bggrEt6nu2bMnzfv06RPM2LbAALB9+3aa9+/fP6f8gw8+CGbbtm2jYwcNGtRmx44dP3bsWAvvHTt20Jy1VWY/TwDo1q0bzT/66COas/biAHDeeecFs5KSEjr26NGjwWzmzJmora21lrIzeTd+FYCWBkfn1EWkeOgKOpFEqNhFEqFiF0mEil0kESp2kUSo2EUSkfetpJuu0WlZbPteNs9eVlZGx8bmRWNLYHv37h3MLrzwQjp2165dNF+7di3Nzz//fJpfdNFFwSy2xXZsCSxrkx07duz4a9asoWNjc+EDBw6kObu2IvbzLi0tpXls2/OGhgaaHzhwIJixxxrA5+FZfemZXSQRKnaRRKjYRRKhYhdJhIpdJBEqdpFEqNhFEhFdz96qBzPbD6D5IuQyAHwCvHCK9dyK9bwAnVu2WvPcznf37i0FeS32fzq4WY27hzdkL6BiPbdiPS9A55atfJ2bXsaLJELFLpKIQhf7rAIfnynWcyvW8wJ0btnKy7kV9Hd2EcmfQj+zi0ieqNhFElGQYjezUWa22cy2mdk9hTiHEDPbbmbvmtlaM6sp8LnMNrN9Zra+2W2lZrbEzLZmPrbYY69A5zbNzHZn7ru1ZnZNgc6tr5ktN7ONZrbBzKZmbi/ofUfOKy/3W95/ZzezswFsAXAVgF0AqgGMc/eNeT2RADPbDqDS3Qt+AYaZXQqgAcDT7j4kc9t/Aah39+mZ/yi7uvvdRXJu0wA0FLqNd6ZbUa/mbcYBXAvgFhTwviPndQPycL8V4pl9GIBt7v6Bux8DMA/A2AKcR9Fz9xUA6j9z81gAVZnPq9D0YMm7wLkVBXevc/c1mc8PAzjdZryg9x05r7woRLFXAGjeL2kXiqvfuwN42cxWm9mkQp9MC8qbtdn6EADfHyn/om288+kzbcaL5r7Lpv15rvQG3T8b4e7/DmA0gDsyL1eLkjf9DlZMc6dn1MY7X1poM/53hbzvsm1/nqtCFPtuAM079vXJ3FYU3H135uM+AAtQfK2o957uoJv5uK/A5/N3xdTGu6U24yiC+66Q7c8LUezVAAaZWX8z6wDgOwAWFeA8/omZdcy8cQIz6wjgahRfK+pFAMZnPh8P4I8FPJd/UCxtvENtxlHg+67g7c/dPe9/AFyDpnfk3wdwfyHOIXBeAwC8k/mzodDnBuBZNL2sO46m9za+B6AbgKUAtgJ4BUBpEZ3bM2hq7b0OTYXVq0DnNgJNL9HXAVib+XNNoe87cl55ud90uaxIIvQGnUgiVOwiiVCxiyRCxS6SCBW7SCJU7CKJULGLJOJ/AbXThoi/77QBAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "bbYVYiF1dKp9",
        "outputId": "436f76d3-c49b-456e-93f5-431fb44c7edb"
      },
      "source": [
        "random_image = np.random.randn(784)\n",
        "random_image = tf.reshape(random_image,(28,28))\n",
        "plt.imshow(random_image,cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f2601747990>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STYXBxxSofFS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}